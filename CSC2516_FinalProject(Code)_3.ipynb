{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paridhika/DDL/blob/main/CSC2516_FinalProject(Code)_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8loDujPQPhrq"
      },
      "source": [
        "# Active Transfer Learning\n",
        "\n",
        "In this project we experiment different active learning setups."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfJnQ9-7yl8O"
      },
      "source": [
        "## Importing the Necessary Packages and Setting GPUs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0-Xc4Y1mq0U",
        "outputId": "746cdc3f-8877-48ba-fbda-86bb26cf94fe"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "import datetime\n",
        "\n",
        "!pip install transformers\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "!pip install modAL\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Collecting modAL\n",
            "  Downloading modal-0.63.46-py3-none-any.whl (498 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.1/498.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from modAL) (3.9.5)\n",
            "Collecting aiostream~=0.5.2 (from modAL)\n",
            "  Downloading aiostream-0.5.2-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from modAL) (2024.6.2)\n",
            "Requirement already satisfied: click>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from modAL) (8.1.7)\n",
            "Collecting fastapi (from modAL)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpclib==0.4.7 (from modAL)\n",
            "  Downloading grpclib-0.4.7.tar.gz (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0,>=3.19 in /usr/local/lib/python3.10/dist-packages (from modAL) (3.20.3)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from modAL) (13.7.1)\n",
            "Collecting synchronicity~=0.6.6 (from modAL)\n",
            "  Downloading synchronicity-0.6.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from modAL) (0.10.2)\n",
            "Requirement already satisfied: typer>=0.9 in /usr/local/lib/python3.10/dist-packages (from modAL) (0.12.3)\n",
            "Collecting types-certifi (from modAL)\n",
            "  Downloading types_certifi-2021.10.8.3-py3-none-any.whl (2.1 kB)\n",
            "Collecting types-toml (from modAL)\n",
            "  Downloading types_toml-0.10.8.20240310-py3-none-any.whl (4.8 kB)\n",
            "Collecting watchfiles (from modAL)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions~=4.6 in /usr/local/lib/python3.10/dist-packages (from modAL) (4.12.2)\n",
            "Collecting h2<5,>=3.1.0 (from grpclib==0.4.7->modAL)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: multidict in /usr/local/lib/python3.10/dist-packages (from grpclib==0.4.7->modAL) (6.0.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->modAL) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->modAL) (2.16.1)\n",
            "Collecting sigtools==4.0.1 (from synchronicity~=0.6.6->modAL)\n",
            "  Downloading sigtools-4.0.1-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from sigtools==4.0.1->synchronicity~=0.6.6->modAL) (23.2.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9->modAL) (1.5.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->modAL) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->modAL) (1.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->modAL) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->modAL) (4.0.3)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->modAL)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi->modAL) (2.8.0)\n",
            "Collecting fastapi-cli>=0.0.2 (from fastapi->modAL)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Collecting httpx>=0.23.0 (from fastapi->modAL)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->modAL) (3.1.4)\n",
            "Collecting python-multipart>=0.0.7 (from fastapi->modAL)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->modAL)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson>=3.2.1 (from fastapi->modAL)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->modAL)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Collecting uvicorn[standard]>=0.12.0 (from fastapi->modAL)\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from watchfiles->modAL) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio>=3.0.0->watchfiles->modAL) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio>=3.0.0->watchfiles->modAL) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio>=3.0.0->watchfiles->modAL) (1.2.1)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->modAL)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperframe<7,>=6.0 (from h2<5,>=3.1.0->grpclib==0.4.7->modAL)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3.1.0->grpclib==0.4.7->modAL)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Collecting httpcore==1.* (from httpx>=0.23.0->fastapi->modAL)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.23.0->fastapi->modAL)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi->modAL) (2.1.5)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->modAL) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->modAL) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->modAL) (2.20.0)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.12.0->fastapi->modAL)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0->fastapi->modAL)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi->modAL) (6.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0->fastapi->modAL)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.12.0->fastapi->modAL)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: grpclib\n",
            "  Building wheel for grpclib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grpclib: filename=grpclib-0.4.7-py3-none-any.whl size=76219 sha256=4618926711ffde19b4106137ad751ceb5f36cbfab63001e6372ad48805c77cd0\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/c0/1c/3d807409d0c67efeab2949832ba409205b1b6fe03f739ae4c1\n",
            "Successfully built grpclib\n",
            "Installing collected packages: types-certifi, websockets, uvloop, ujson, types-toml, sigtools, python-multipart, python-dotenv, orjson, hyperframe, httptools, hpack, h11, dnspython, aiostream, watchfiles, uvicorn, synchronicity, starlette, httpcore, h2, email_validator, httpx, grpclib, fastapi-cli, fastapi, modAL\n",
            "Successfully installed aiostream-0.5.2 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.0 fastapi-cli-0.0.4 grpclib-0.4.7 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 hyperframe-6.0.1 modAL-0.63.46 orjson-3.10.6 python-dotenv-1.0.1 python-multipart-0.0.9 sigtools-4.0.1 starlette-0.37.2 synchronicity-0.6.7 types-certifi-2021.10.8.3 types-toml-0.10.8.20240310 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z7xhV_DPAz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c70ce64-c6f3-4b7e-8a2f-27911b5dd581"
      },
      "source": [
        "# Get the GPU device name\n",
        "device_name=tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following\n",
        "if device_name=='/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMhaZEKEPIJ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "623ef832-c169-4d4c-831e-c783e89bfb44"
      },
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU\n",
        "    device=torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device=torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second\n",
        "    elapsed_rounded=int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "WkSkme4-1QMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqKg1VPGPgL6"
      },
      "source": [
        "## Loading and Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOcePxwdUjcd"
      },
      "source": [
        "topic_num=0\n",
        "\n",
        "all_topics=pickle.load(open(\"all_topics_with_meta.p\",\"rb\"))\n",
        "data=pd.DataFrame.from_dict(all_topics[0]).T\n",
        "data['topic']=0\n",
        "tags=data.tag.values\n",
        "\n",
        "for i in range(1,9):\n",
        "  topic=pd.DataFrame.from_dict(all_topics[i]).T\n",
        "  topic['topic']=i\n",
        "  data=pd.concat([data,topic],axis=0)\n",
        "\n",
        "\n",
        "# Converting boolean features into integers in the dataset\n",
        "map={\"rumours\":1,\"non-rumours\":0}\n",
        "data=data.replace({'tag':map})\n",
        "map={\"photo\":1,\"none\":0}\n",
        "data=data.replace({'media_type':map})\n",
        "map={True:1,False:0}\n",
        "data=data.replace({'verified':map})\n",
        "\n",
        "\n",
        "# Normalizing features\n",
        "import copy\n",
        "df=copy.deepcopy(data)\n",
        "cols=['favorite_count_log','retweet_count','followers','follow_ratio','length','capital_ratio']\n",
        "for item in cols:\n",
        "  column=item\n",
        "  df[column]=(df[column]-df[column].min())/(df[column].max()-df[column].min())\n",
        "\n",
        "\n",
        "data=df\n",
        "train_df=data[data['topic']!=topic_num]\n",
        "train_sentences=train_df.text.values\n",
        "train_labels=train_df.tag.values\n",
        "\n",
        "test_df=data[data['topic']==topic_num]\n",
        "test_sentences=test_df.text.values\n",
        "test_labels=test_df.tag.values\n",
        "\n",
        "\n",
        "data2=data.reset_index()\n",
        "def pd_iter_func(df,topic):\n",
        "    for row in df.itertuples():\n",
        "        # Define your criteria here\n",
        "        if row.topic==topic:\n",
        "            return row\n",
        "\n",
        "start_test=pd_iter_func(data2,topic_num).Index\n",
        "\n",
        "if topic_num==8:\n",
        "  end_test=len(data2)\n",
        "else:\n",
        "  end_test=pd_iter_func(data2,topic_num+1).Index-1\n",
        "\n",
        "train_start=start_test\n",
        "train_end=end_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Active Learning Multiple Runs\n",
        "Since every model might have a different input and output and training specific setting, we have multiple functions for a different model. The Multipart comes from the fact that we need to run the model multiple times to avoid the randomness effect of selecting a specific train test. We do this because our data set is around 2k, and we want concrete results.\n"
      ],
      "metadata": {
        "id": "uY0RdW2xskeX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH4DI_eYiqIY"
      },
      "source": [
        "### run_multy_epsilon_greedy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from modAL.models import ActiveLearner\n",
        "from modAL.batch import uncertainty_batch_sampling\n",
        "from modAL.uncertainty import uncertainty_sampling\n",
        "\n",
        "from functools import partial\n",
        "from collections import Counter\n",
        "\n",
        "!pip install scikeras\n",
        "from scikeras.wrappers import KerasClassifier"
      ],
      "metadata": {
        "id": "jTs4l8HGIX4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ed71853-1634-496e-a128-b2d50d0ad973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikeras in /usr/local/lib/python3.9/dist-packages (0.10.0)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.9/dist-packages (from scikeras) (23.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikeras) (1.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.22.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiW-lOdUiy_j"
      },
      "source": [
        "def run_multy_epsilon_greedy(BATCH_SIZE, data_test, test_labels, num_of_run, model_name, strategy, train_size, is_random):\n",
        "\n",
        "  test_pool_split=0.5\n",
        "  preset_batch=partial(strategy, n_instances=40)\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(data_test, test_labels, test_size=train_size, shuffle=True)\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(X_pool_0, y_pool_0, test_size=test_pool_split, shuffle=True )\n",
        "  N_QUERIES=int(len(X_pool_0)/BATCH_SIZE)\n",
        "\n",
        "  pref_hist_multy_accuracy=np.zeros((num_of_run, N_QUERIES+1))\n",
        "  pref_hist_multy_f1=np.zeros((num_of_run, N_QUERIES+1))\n",
        "  pref_hist_majority=np.zeros((num_of_run, N_QUERIES+1))\n",
        "  pref_confusion=np.zeros((num_of_run, N_QUERIES+1,4))\n",
        "  pref_random=0\n",
        "\n",
        "  for i in range(num_of_run):\n",
        "    clf = get_model(model_name)\n",
        "\n",
        "    X_pool, X_train, y_pool, y_train = train_test_split(data_test, test_labels, test_size=train_size, shuffle=True, random_state=random_seed_list[i])\n",
        "    X_pool, X_test, y_pool, y_test   = train_test_split(X_pool, y_pool, test_size=test_pool_split, shuffle=True, random_state=random_seed_list[i])\n",
        "\n",
        "    learner=ActiveLearner(\n",
        "        estimator=clf,\n",
        "        query_strategy=preset_batch,\n",
        "        X_training=X_train,\n",
        "        y_training=y_train)\n",
        "\n",
        "    t1=time.time()\n",
        "\n",
        "    # Allow our model to query our unlabeled dataset for the most informative points according to our query strategy (uncertainty sampling).\n",
        "    counter_random= 1\n",
        "\n",
        "    # Calculate initial batch\n",
        "    y_pred=learner.predict(X_test)\n",
        "    macro=f1_score(y_test,y_pred, average='macro')\n",
        "    pref_hist_multy_f1[i][0]=macro\n",
        "    tn, fp, fn, tp=confusion_matrix(y_test, y_pred).ravel()\n",
        "    pref_confusion[i][0]=[tn, fp, fn, tp]\n",
        "\n",
        "    # Calculate initial batch majority\n",
        "    counts=np.bincount(y_train)\n",
        "    value=np.argmax(counts)\n",
        "    majority=[value for i in range(len(y_test))]\n",
        "    macro=f1_score(y_test,majority, average='macro')\n",
        "    pref_hist_majority[i][0]=macro\n",
        "\n",
        "    # Calculate random\n",
        "    y_rand=[random.randint(0,2) for i in range(len(y_test))]\n",
        "    macro=f1_score(y_test, y_rand, average='macro')\n",
        "    pref_random=pref_random + macro\n",
        "\n",
        "\n",
        "    # Active Leraning loop\n",
        "    for index in range(1, N_QUERIES+1):\n",
        "      counter_random += 1\n",
        "      t2=time.time()\n",
        "      print(i,'th run and query number',index)\n",
        "      if not is_random:\n",
        "        query_index, query_instance=learner.query(X_pool)\n",
        "        print('num if query',len(query_index))\n",
        "\n",
        "      if is_random:\n",
        "        index_list=range(len(X_pool))\n",
        "        query_index=random.sample(index_list, BATCH_SIZE)\n",
        "\n",
        "      X, y = X_pool[query_index], y_pool[query_index]\n",
        "      learner.teach(X=X, y=y)\n",
        "\n",
        "      # Remove the queried instance from the unlabeled pool.\n",
        "      X_pool, y_pool=np.delete(X_pool, query_index, axis=0), np.delete(y_pool, query_index,axis=0)\n",
        "\n",
        "      index_list=range(len(X_pool))\n",
        "      query_index=random.sample(index_list, 10)\n",
        "\n",
        "      X, y = X_pool[query_index], y_pool[query_index]\n",
        "      learner.teach(X=X, y=y)\n",
        "\n",
        "      X_pool, y_pool=np.delete(X_pool, query_index, axis=0), np.delete(y_pool, query_index,axis=0)\n",
        "\n",
        "      # Calculate and report our model's accuracy.\n",
        "      model_accuracy=learner.score(X_test, y_test)\n",
        "      y_pred=learner.predict(X_test)\n",
        "      macro=f1_score( y_test, y_pred, average='macro')\n",
        "      print('after query {n}: Accuracy :{acc:0.4f} macro f1 :{f1:0.4f}'.format(n=index + 1, acc=model_accuracy,f1=macro))\n",
        "\n",
        "      # Save our model's performance for plotting.\n",
        "      tn, fp, fn, tp=confusion_matrix(y_test,y_pred).ravel()\n",
        "      pref_confusion[i][index]=[tn, fp, fn, tp]\n",
        "      pref_hist_multy_accuracy[i][index]=model_accuracy\n",
        "      pref_hist_multy_f1[i][index]=macro\n",
        "\n",
        "      # Calculate and add majority\n",
        "      counts=np.bincount(y_train)\n",
        "      value=np.argmax(counts)\n",
        "      majority=[value for i in range(len(y_test))]\n",
        "      macro=f1_score(y_test,majority, average='macro')\n",
        "      pref_hist_majority[i][index]=macro\n",
        "      print(format_time(time.time()-t2))\n",
        "\n",
        "    print(format_time(time.time()-t1))\n",
        "    pref_random= pref_random/num_of_run\n",
        "    pref_hist_majority_avg=pref_hist_majority.mean(0)\n",
        "    pref_hist_multy_acc_avg=pref_hist_multy_accuracy.mean(0)\n",
        "    pref_hist_multy_f1_avg=pref_hist_multy_f1.mean(0)\n",
        "\n",
        "  return pref_hist_multy_accuracy, pref_hist_multy_f1, pref_random, pref_hist_majority, N_QUERIES"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r1Z3f4X-lsu"
      },
      "source": [
        "### run_multy_sklearn()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from modAL.models import ActiveLearner\n",
        "from modAL.batch import uncertainty_batch_sampling\n",
        "from modAL.uncertainty import uncertainty_sampling\n",
        "\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "from functools import partial\n",
        "from collections import Counter\n",
        "\n",
        "random_seed_list=[5,12,42,29,54]"
      ],
      "metadata": {
        "id": "oIERvMQ42WpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6thIy2-n-qLt"
      },
      "source": [
        "def run_multy_sklearn(BATCH_SIZE, data_test, test_labels, num_of_run, model_name, strategy, train_size, is_random):\n",
        "\n",
        "  test_pool_split=0.5\n",
        "  preset_batch=partial(strategy, n_instances=BATCH_SIZE)\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(data_test, test_labels, test_size=train_size, shuffle=True )\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(X_pool_0, y_pool_0, test_size=test_pool_split, shuffle=True )\n",
        "  N_QUERIES=int(len(X_pool_0)/BATCH_SIZE)\n",
        "\n",
        "  pref_hist_multy_accuracy=np.zeros((num_of_run, N_QUERIES+1))\n",
        "  pref_hist_multy_f1=np.zeros((num_of_run, N_QUERIES+1))\n",
        "  pref_hist_majority=np.zeros((num_of_run, N_QUERIES+1))\n",
        "  pref_random=0\n",
        "\n",
        "  for i in range(num_of_run):\n",
        "    clf=get_model(model_name)\n",
        "\n",
        "    X_pool, X_train, y_pool, y_train = train_test_split(data_test, test_labels, test_size=train_size, shuffle=True, random_state=random_seed_list[i])\n",
        "    X_pool, X_test, y_pool, y_test = train_test_split(X_pool, y_pool, test_size=test_pool_split, shuffle=True, random_state=random_seed_list[i])\n",
        "\n",
        "    learner = ActiveLearner(\n",
        "        estimator=clf,\n",
        "        query_strategy=preset_batch,\n",
        "        X_training=X_train,\n",
        "        y_training=y_train)\n",
        "\n",
        "    t1 = time.time()\n",
        "\n",
        "    # Allow our model to query our unlabeled dataset for the most informative points according to our query strategy (uncertainty sampling).\n",
        "    # counter_random= 1\n",
        "\n",
        "    # Calculate initial batch\n",
        "    y_pred=learner.predict(X_test)\n",
        "    macro=f1_score(y_test, y_pred, average='macro')\n",
        "    pref_hist_multy_f1[i][0]=macro\n",
        "\n",
        "    # Calculate initial batch majority\n",
        "    counts=np.bincount(y_train)\n",
        "    value=np.argmax(counts)\n",
        "    majority=[value for i in range(len(y_test))]\n",
        "    macro=f1_score(y_test, majority, average='macro')\n",
        "    pref_hist_majority[i][0]=macro\n",
        "\n",
        "    # Calculate random\n",
        "    y_rand=[random.randint(0,2) for i in range(len(y_test))]\n",
        "    macro=f1_score( y_test,y_rand, average='macro')\n",
        "    pref_random=pref_random + macro\n",
        "\n",
        "    # Active leraning loop\n",
        "    for index in range(1,N_QUERIES+1):\n",
        "      # Counter_random += 1\n",
        "      t2 = time.time()\n",
        "      print(i,'th run and query number',index)\n",
        "      query_index, query_instance = learner.query(X_pool)\n",
        "      print('num if query',len(query_index))\n",
        "\n",
        "      if is_random : # or counter_random % random_ratio == 0:\n",
        "        index_list=range(len(X_pool))\n",
        "        query_index=random.sample(index_list,BATCH_SIZE)\n",
        "\n",
        "      # Teach our ActiveLearner model the record it has requested.\n",
        "      X, y = X_pool[query_index], y_pool[query_index]\n",
        "\n",
        "      for j in range(1):\n",
        "        learner.teach(X=X, y=y)\n",
        "\n",
        "      # Remove the queried instance from the unlabeled pool.\n",
        "      X_pool, y_pool = np.delete(X_pool, query_index, axis=0), np.delete(y_pool, query_index,axis=0)\n",
        "\n",
        "      # Calculate and report our model's accuracy.\n",
        "      model_accuracy=learner.score(X_test, y_test)\n",
        "      y_pred=learner.predict(X_test)\n",
        "      macro=f1_score(y_test, y_pred, average='macro')\n",
        "      print('after query {n}: Accuracy :{acc:0.4f} macro f1 :{f1:0.4f}'.format(n=index + 1, acc=model_accuracy, f1=macro))\n",
        "\n",
        "      # Save our model's performance for plotting.\n",
        "      pref_hist_multy_accuracy[i][index]=model_accuracy\n",
        "      pref_hist_multy_f1[i][index]=macro\n",
        "\n",
        "      # Calculate and add majority\n",
        "      counts=np.bincount(y_train)\n",
        "      value=np.argmax(counts)\n",
        "      majority=[value for i in range(len(y_test))]\n",
        "      macro=f1_score(y_test,majority, average='macro')\n",
        "      pref_hist_majority[i][index]=macro\n",
        "\n",
        "      print(format_time(time.time()-t2))\n",
        "      print(format_time(time.time()-t1))\n",
        "      pref_random= pref_random/num_of_run\n",
        "      pref_hist_majority_avg=pref_hist_majority.mean(0)\n",
        "      pref_hist_multy_acc_avg=pref_hist_multy_accuracy.mean(0)\n",
        "      pref_hist_multy_f1_avg=pref_hist_multy_f1.mean(0)\n",
        "\n",
        "  return pref_hist_multy_acc_avg, pref_hist_multy_f1_avg, pref_random, pref_hist_majority_avg, N_QUERIES\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GAW2YLTWb73"
      },
      "source": [
        "### run_multy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from modAL.models import ActiveLearner\n",
        "from modAL.batch import uncertainty_batch_sampling\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "random_seed_list=[5,12,42,29,54]"
      ],
      "metadata": {
        "id": "IBSwxV7h44IA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJzQWwYOTHVc"
      },
      "source": [
        "def run_multy(BATCH_SIZE, data_test, test_labels, num_of_run, model, strategy, train_size, is_random):\n",
        "\n",
        "  test_pool_split=0.5\n",
        "  preset_batch=partial(strategy, n_instances=BATCH_SIZE)\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(data_test, test_labels, test_size=train_size, shuffle=True )\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(X_pool_0, y_pool_0, test_size=test_pool_split, shuffle=True )\n",
        "  N_QUERIES=int(len(X_pool_0)/BATCH_SIZE)\n",
        "  print(num_of_run, N_QUERIES)\n",
        "\n",
        "  pref_hist_multy_accuracy=np.zeros((num_of_run, N_QUERIES+1))\n",
        "  pref_hist_multy_f1=np.zeros((num_of_run, N_QUERIES+1))\n",
        "  pref_hist_majority=np.zeros((num_of_run, N_QUERIES+1))\n",
        "  pref_random=0\n",
        "\n",
        "  test_labels=keras.utils.to_categorical(test_labels, 2)\n",
        "\n",
        "  for i in range(num_of_run):\n",
        "    X_pool, X_train, y_pool, y_train = train_test_split(data_test, test_labels, test_size=train_size, shuffle=True, random_state=random_seed_list[i])\n",
        "    X_pool, X_test, y_pool, y_test = train_test_split(X_pool, y_pool, test_size=test_pool_split, shuffle=True, random_state=random_seed_list[i])\n",
        "\n",
        "    clf = KerasClassifier(model)\n",
        "    ## clf = get_model(model)\n",
        "\n",
        "    print('x pool length', X_train.shape)\n",
        "    print('y pool length', y_train.shape)\n",
        "\n",
        "    learner = ActiveLearner(\n",
        "        estimator=clf,\n",
        "        query_strategy=preset_batch,\n",
        "        X_training=X_train,\n",
        "        y_training=y_train)\n",
        "\n",
        "    t1 = time.time()\n",
        "\n",
        "    # Allow our model to query our unlabeled dataset for the most informative points according to our query strategy (uncertainty sampling).\n",
        "    # Calculate initial batch\n",
        "    y_pred=learner.predict(X_test)\n",
        "    y_pred=y_pred[:,1]\n",
        "    y_test_cat = np.argmax(y_test,axis=1)\n",
        "    macro=f1_score(y_test_cat, y_pred, average='macro')\n",
        "    pref_hist_multy_f1[i][0]=macro\n",
        "\n",
        "    # Calculate initial batch majority\n",
        "    y_train_cat=np.argmax(y_test,axis=1)\n",
        "    counts=np.bincount(y_train_cat)\n",
        "    value=np.argmax(counts)\n",
        "    majority=[value for i in range(len(y_test_cat))]\n",
        "    macro=f1_score(y_test_cat, majority, average='macro')\n",
        "    pref_hist_majority[i][0]=macro\n",
        "\n",
        "    # Calculate random\n",
        "    y_rand=[random.randint(0,2) for i in range(len(y_test_cat))]\n",
        "    macro=f1_score(y_test_cat, y_rand, average='macro')\n",
        "    pref_random=pref_random + macro\n",
        "\n",
        "    for index in range(1,N_QUERIES+1):\n",
        "      query_index, query_instance=learner.query(X_pool)\n",
        "      # print('num if query',len(query_index))\n",
        "\n",
        "      if is_random:\n",
        "        index_list=range(len(X_pool))\n",
        "        query_index=random.sample(index_list,BATCH_SIZE)\n",
        "\n",
        "      # Teach our ActiveLearner model the record it has requested.\n",
        "      X, y = X_pool[query_index], y_pool[query_index]\n",
        "\n",
        "      for j in range(5):\n",
        "        learner.teach(X=X, y=y)\n",
        "\n",
        "      # Remove the queried instance from the unlabeled pool.\n",
        "      X_pool, y_pool = np.delete(X_pool, query_index, axis=0), np.delete(y_pool, query_index,axis=0)\n",
        "      print('sec',y_pool.shape)\n",
        "\n",
        "      # Calculate and report our model's accuracy.\n",
        "      model_accuracy=learner.score(data_test, test_labels)\n",
        "      y_pred=learner.predict(X_test)\n",
        "      y_pred=y_pred[:,1]\n",
        "\n",
        "      y_test_cat=np.argmax(y_test,axis=1)\n",
        "      # print('shapeè',y_test_cat.shape)\n",
        "      macro=f1_score(y_test_cat, y_pred, average='macro')\n",
        "      print('after query {n}: Accuracy :{acc:0.4f} macro f1 :{f1:0.4f}'.format(n=index + 1, acc=model_accuracy, f1=macro))\n",
        "\n",
        "      # Save our model's performance for plotting.\n",
        "      pref_hist_multy_accuracy[i][index]=model_accuracy\n",
        "      pref_hist_multy_f1[i][index]=macro\n",
        "\n",
        "      # Calculate and add majority\n",
        "      y_train_cat=np.argmax(y_test, axis=1)\n",
        "      counts=np.bincount(y_train_cat)\n",
        "      value=np.argmax(counts)\n",
        "      majority =[value for i in range(len(y_test_cat))]\n",
        "      macro=f1_score(y_test_cat, majority, average='macro')\n",
        "      pref_hist_majority[i][index]=macro\n",
        "\n",
        "    print(format_time(time.time()-t1))\n",
        "    pref_random= pref_random/num_of_run\n",
        "    pref_hist_majority_avg=pref_hist_majority.mean(0)\n",
        "    pref_hist_multy_acc_avg=pref_hist_multy_accuracy.mean(0)\n",
        "    pref_hist_multy_f1_avg=pref_hist_multy_f1.mean(0)\n",
        "\n",
        "  return pref_hist_multy_acc_avg, pref_hist_multy_f1_avg, pref_random, pref_hist_majority_avg, N_QUERIES\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOYSeV_xX7nt"
      },
      "source": [
        "### run_multy_committe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from modAL.models import ActiveLearner\n",
        "from modAL.models import ActiveLearner, Committee\n",
        "from modAL.batch import uncertainty_batch_sampling\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "random_seed_list=[5,12,42,29,54]"
      ],
      "metadata": {
        "id": "nwHjpQ1T7xPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BksKfnVnX4qn"
      },
      "source": [
        "commite_size = 5\n",
        "def run_multy_commite(BATCH_SIZE, data_test, test_labels, num_of_run,model_name, strategy, train_size, is_random, mode):\n",
        "\n",
        "  test_pool_split=0.5\n",
        "  preset_batch=partial(strategy, n_instances=BATCH_SIZE)\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(data_test, test_labels, test_size=train_size,shuffle=True )\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(X_pool_0, y_pool_0, test_size=test_pool_split,shuffle=True )\n",
        "  N_QUERIES=int(len(X_pool_0)/BATCH_SIZE)\n",
        "\n",
        "  pref_hist_multy_accuracy=np.zeros((num_of_run, N_QUERIES+1))\n",
        "  pref_hist_multy_f1=np.zeros((num_of_run, N_QUERIES+1))\n",
        "  pref_hist_majority=np.zeros((num_of_run, N_QUERIES+1))\n",
        "\n",
        "  pref_random=0\n",
        "  boost=False\n",
        "  if mode=='boost'or mode=='bag':\n",
        "    boost=True\n",
        "\n",
        "  for i in range(num_of_run):\n",
        "    clf=get_model(model_name)\n",
        "\n",
        "    X_pool, X_train, y_pool, y_train = train_test_split(data_test, test_labels, test_size=train_size, shuffle=True, random_state=random_seed_list[i])\n",
        "    X_pool, X_test, y_pool, y_test = train_test_split(X_pool, y_pool, test_size=test_pool_split, shuffle=True, random_state=random_seed_list[i])\n",
        "\n",
        "    learner_list=[]\n",
        "    for j in range(commite_size):\n",
        "      learner = ActiveLearner(\n",
        "          estimator=clf,\n",
        "          query_strategy=preset_batch,\n",
        "          X_training=X_train,\n",
        "          y_training=y_train,\n",
        "          bootstrap_init=boost,)\n",
        "\n",
        "      learner_list.append(learner)\n",
        "\n",
        "    committee=Committee(learner_list=learner_list)\n",
        "    if mode=='bag':\n",
        "      committee.rebag()\n",
        "\n",
        "    t1=time.time()\n",
        "\n",
        "    # Calculate initial batch\n",
        "    y_pred=committee.predict(X_test)\n",
        "    macro=f1_score(y_test,y_pred, average='macro')\n",
        "    pref_hist_multy_f1[i][0]=macro\n",
        "\n",
        "    # Calculate initial batch majority\n",
        "    counts=np.bincount(y_train)\n",
        "    value=np.argmax(counts)\n",
        "    majority=[value for i in range(len(y_test))]\n",
        "    macro=f1_score(y_test,majority, average='macro')\n",
        "    pref_hist_majority[i][0]=macro\n",
        "\n",
        "    # Calculate random\n",
        "    y_rand=[random.randint(0,2) for i in range(len(y_test))]\n",
        "    macro=f1_score( y_test,y_rand, average='macro')\n",
        "    pref_random=pref_random + macro\n",
        "\n",
        "    # Active leraning loop\n",
        "    for index in range(1,N_QUERIES+1):\n",
        "      t2=time.time()\n",
        "\n",
        "      query_index, query_instance=committee.query(X_pool)\n",
        "\n",
        "      if is_random : # or counter_random % random_ratio == 0:\n",
        "        index_list=range(len(X_pool))\n",
        "        query_index=random.sample(index_list,BATCH_SIZE)\n",
        "\n",
        "      X, y = X_pool[query_index], y_pool[query_index]\n",
        "\n",
        "      for j in range(1):\n",
        "        committee.teach(X=X, y=y)\n",
        "\n",
        "      # Remove the queried instance from the unlabeled pool.\n",
        "      X_pool, y_pool = np.delete(X_pool, query_index, axis=0), np.delete(y_pool, query_index,axis=0)\n",
        "\n",
        "      # Calculate and report our model's accuracy.\n",
        "      model_accuracy=committee.score(X_test, y_test)\n",
        "      y_pred=committee.predict(X_test)\n",
        "      macro=f1_score( y_test,y_pred, average='macro')\n",
        "      print('after query {n}: Accuracy :{acc:0.4f} macro f1 :{f1:0.4f}'.format(n=index + 1, acc=model_accuracy,f1=macro))\n",
        "\n",
        "      pref_hist_multy_accuracy[i][index]=model_accuracy\n",
        "      pref_hist_multy_f1[i][index]=macro\n",
        "\n",
        "      # Calculate and add majority\n",
        "      counts=np.bincount(y_train)\n",
        "      value=np.argmax(counts)\n",
        "      majority=[value for i in range(len(y_test))]\n",
        "      macro=f1_score(y_test,majority, average='macro')\n",
        "      pref_hist_majority[i][index]=macro\n",
        "      print(format_time(time.time()-t2))\n",
        "\n",
        "    print(format_time(time.time()-t1))\n",
        "    pref_random= pref_random/num_of_run\n",
        "    pref_hist_majority_avg=pref_hist_majority.mean(0)\n",
        "    pref_hist_multy_acc_avg=pref_hist_multy_accuracy.mean(0)\n",
        "    pref_hist_multy_f1_avg=pref_hist_multy_f1.mean(0)\n",
        "\n",
        "  return pref_hist_multy_accuracy, pref_hist_multy_f1, pref_random, pref_hist_majority, N_QUERIES"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuaLfSdd36WP"
      },
      "source": [
        "\n",
        "\n",
        "### run_multy_cross()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddCV-3MT3_BL"
      },
      "source": [
        "def run_multy_cross(BATCH_SIZE, data_test, test_labels, num_of_run, model_name, strategy, train_size, is_random):\n",
        "\n",
        "  test_pool_split=0.5\n",
        "  preset_batch=partial(strategy, n_instances=40)\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(data_test, test_labels, test_size=train_size, shuffle=True )\n",
        "  X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(X_pool_0, y_pool_0, test_size=test_pool_split, shuffle=True )\n",
        "  N_QUERIES=int(len(X_pool_0)/BATCH_SIZE)\n",
        "\n",
        "  pref_hist_multy_accuracy=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_hist_multy_f1=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_hist_majority=np.zeros((num_of_run,N_QUERIES+1))\n",
        "  pref_random = 0\n",
        "\n",
        "  for i in range(num_of_run):\n",
        "    clf=get_model(model_name)\n",
        "\n",
        "    X_pool, X_train, y_pool, y_train = train_test_split(data_test, test_labels, test_size=train_size, shuffle=True, random_state=random_seed_list[i])\n",
        "    X_pool, X_test, y_pool, y_test = train_test_split(X_pool, y_pool, test_size=test_pool_split, shuffle=True, random_state=random_seed_list[i])\n",
        "\n",
        "    learner = ActiveLearner(\n",
        "        estimator=clf,\n",
        "        query_strategy=preset_batch,\n",
        "        X_training=X_train,\n",
        "        y_training=y_train)\n",
        "\n",
        "    t1 = time.time()\n",
        "\n",
        "\n",
        "    #Allow our model to query our unlabeled dataset for the most informative points according to our query strategy (uncertainty sampling)\n",
        "    counter_random= 1\n",
        "\n",
        "    # Calculate initial batch\n",
        "    y_pred=learner.predict(X_test)\n",
        "    macro=f1_score(y_test,y_pred, average='macro')\n",
        "    pref_hist_multy_f1[i][0]=macro\n",
        "\n",
        "    # Calculate initial batch majority\n",
        "    counts=np.bincount(y_train)\n",
        "    value=np.argmax(counts)\n",
        "    majority=[value for i in range(len(y_test))]\n",
        "    macro=f1_score(y_test,majority, average='macro')\n",
        "    pref_hist_majority[i][0]=macro\n",
        "\n",
        "    # Calculate random\n",
        "    y_rand=[random.randint(0,2) for i in range(len(y_test))]\n",
        "    macro=f1_score(y_test, y_rand, average='macro')\n",
        "    pref_random = pref_random + macro\n",
        "\n",
        "    # Active Leraning loop\n",
        "    for index in range(1, N_QUERIES+1):\n",
        "      counter_random += 1\n",
        "      t2=time.time()\n",
        "      print(i,'th run and query number',index)\n",
        "\n",
        "      query_index, query_instance = learner.query(X_pool)\n",
        "      print('num if query',len(query_index))\n",
        "\n",
        "      if is_random:\n",
        "        index_list=range(len(X_pool))\n",
        "        query_index=random.sample(index_list, BATCH_SIZE)\n",
        "\n",
        "      X, y = X_pool[query_index], y_pool[query_index]\n",
        "      for j in range(1):\n",
        "        learner.teach(X=X, y=y)\n",
        "\n",
        "      # Remove the queried instance from the unlabeled pool.\n",
        "      X_pool, y_pool = np.delete(X_pool, query_index, axis=0), np.delete(y_pool, query_index,axis=0)\n",
        "      index_list=range(len(X_pool))\n",
        "      query_index=random.sample(index_list,10)\n",
        "\n",
        "      X, y = X_pool[query_index], y_pool[query_index]\n",
        "      X_train=np.concatenate((X_train, X))\n",
        "      y_train=np.concatenate((y_train, y))\n",
        "\n",
        "      for j in range(1):\n",
        "        learner.teach(X=X, y=y)\n",
        "\n",
        "      X_pool, y_pool = np.delete(X_pool, query_index, axis=0), np.delete(y_pool, query_index,axis=0)\n",
        "\n",
        "      # Calculate and report our model's accuracy.\n",
        "      model_accuracy=learner.score(X_test, y_test)\n",
        "      y_pred=learner.predict(X_test)\n",
        "      macro=f1_score(y_test, y_pred, average='macro')\n",
        "      print('after query {n}: Accuracy :{acc:0.4f} macro f1 :{f1:0.4f}'.format(n=index + 1, acc=model_accuracy,f1=macro))\n",
        "\n",
        "      # Save our model's performance for plotting.\n",
        "      pref_hist_multy_accuracy[i][index]=model_accuracy\n",
        "      pref_hist_multy_f1[i][index]=macro\n",
        "\n",
        "      # Calculate and add majority\n",
        "      counts=np.bincount(y_train)\n",
        "      value=np.argmax(counts)\n",
        "      majority=[value for i in range(len(y_test))]\n",
        "      macro=f1_score(y_test,majority, average='macro')\n",
        "      pref_hist_majority[i][index]=macro\n",
        "      print(format_time(time.time()-t2))\n",
        "\n",
        "  print(format_time(time.time()-t1))\n",
        "  pref_random=pref_random/num_of_run\n",
        "  pref_hist_majority_avg=pref_hist_majority.mean(0)\n",
        "  pref_hist_multy_acc_avg=pref_hist_multy_accuracy.mean(0)\n",
        "  pref_hist_multy_f1_avg=pref_hist_multy_f1.mean(0)\n",
        "\n",
        "  return pref_hist_multy_accuracy, pref_hist_multy_f1, pref_random, pref_hist_majority, N_QUERIES"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_3jwCE8sQ3Q"
      },
      "source": [
        "### MLP Model\n",
        "#### create_keras_model_berts() \\& create_keras_model_GLOVE()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv1D, GlobalMaxPooling1D, Activation\n",
        "from keras.layers import Embedding, LSTM\n",
        "\n",
        "from scikeras.wrappers import KerasClassifier"
      ],
      "metadata": {
        "id": "BvA25y7gCgoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_keras_model_berts():\n",
        "  model=Sequential()\n",
        "  model.add(keras.Input(shape=(64,),name=\"source\"))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dropout(0.3))\n",
        "  # model.add(Dense(64, activation='relu'))\n",
        "  # model.add(Dropout(0.3))\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def create_keras_model_GLOVE():\n",
        "  model=Sequential()\n",
        "  model.add(keras.Input(shape=(50,),name=\"source\"))\n",
        "  model.add(Dense(250, activation='relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "  # model.add(Dense(128, activation='relu'))\n",
        "  # model.add(Dropout(0.5))\n",
        "  # model.add(Dense(64, activation='relu'))\n",
        "  # model.add(Dropout(0.5))\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "VepX1HYwd5Ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get_model()\\_Other ML Models"
      ],
      "metadata": {
        "id": "OuHBSHj33O3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "eBJNwHhUC4eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(model_name):\n",
        "\n",
        "  if model_name==\"mlp\":\n",
        "    clf = MLPClassifier(hidden_layer_sizes=(10,), max_iter=1000)\n",
        "\n",
        "  if model_name==\"bag\":\n",
        "    clf = BaggingClassifier(base_estimator=LogisticRegression(), n_estimators=100, max_samples=0.8)\n",
        "\n",
        "  if model_name==\"gbc\":\n",
        "    clf = GradientBoostingClassifier(n_estimators=200, learning_rate=1, max_depth=1)\n",
        "\n",
        "  if model_name==\"ada\":\n",
        "    clf = AdaBoostClassifier(n_estimators=200,learning_rate=0.01)\n",
        "\n",
        "  if model_name==\"svm\":\n",
        "    clf=svm.SVC(probability=True)\n",
        "\n",
        "  if model_name==\"rf\":\n",
        "    clf=RandomForestClassifier(max_depth=1000, random_state=0)\n",
        "\n",
        "  if model_name==\"lr\":\n",
        "    clf=LogisticRegression(random_state=0,class_weight='balanced')\n",
        "\n",
        "  if model_name==\"knn3\":\n",
        "    clf=KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "  if model_name==\"knn5\":\n",
        "    clf=KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "  if model_name==\"lda\":\n",
        "    clf=LinearDiscriminantAnalysis()\n",
        "\n",
        "  if model_name==\"qda\":\n",
        "    clf=QuadraticDiscriminantAnalysis()\n",
        "\n",
        "  return clf"
      ],
      "metadata": {
        "id": "TuYbVoY3_aSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dimension Reduction with PCA for All Features (befor Metadata)"
      ],
      "metadata": {
        "id": "6jBdLtbNtueU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "javxNGJmFCOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca=PCA(0.75)\n",
        "sentence_feature_normal  =pca.fit_transform(np.load('normal_bert.npy'))\n",
        "sentence_feature_tweet   =pca.fit_transform(np.load('tweet_bert.npy'))\n",
        "sentence_feature_GLOVE   =pca.fit_transform(np.load('GLOVE.np'))\n",
        "sentence_feature_GLOVE25 =pca.fit_transform(np.load('GLOVE25.np'))\n",
        "sentence_feature_GLOVE50 =pca.fit_transform(np.load('GLOVE50.np'))\n",
        "sentence_feature_GLOVE100=pca.fit_transform(np.load('GLOVE100.np'))\n"
      ],
      "metadata": {
        "id": "tJCDwTJD1Mpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentence Features Concatenated with Metadata"
      ],
      "metadata": {
        "id": "326zohgZ-Pd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s0=data[cols]\n",
        "s1=pd.DataFrame(sentence_feature_normal)\n",
        "s2=pd.DataFrame(sentence_feature_GLOVE)\n",
        "s3=pd.DataFrame(sentence_feature_GLOVE25)\n",
        "s4=pd.DataFrame(sentence_feature_GLOVE50)\n",
        "s5=pd.DataFrame(sentence_feature_GLOVE100)\n",
        "s6=pd.DataFrame(sentence_feature_tweet)\n",
        "s1.reset_index(drop=True,inplace=True)\n",
        "s0.reset_index(drop=True,inplace=True)\n",
        "s3.reset_index(drop=True,inplace=True)\n",
        "s2.reset_index(drop=True,inplace=True)\n",
        "s1.reset_index(drop=True,inplace=True)\n",
        "s5.reset_index(drop=True,inplace=True)\n",
        "s6.reset_index(drop=True,inplace=True)\n",
        "\n",
        "sentence_feature_normal_new  =pd.concat([s1,s0],axis=1)\n",
        "sentence_feature_tweet_new   =pd.concat([s6,s0],axis=1)\n",
        "sentence_feature_GLOVE_new   =pd.concat([s2,s0],axis=1)\n",
        "sentence_feature_GLOVE25_new =pd.concat([s3,s0],axis=1)\n",
        "sentence_feature_GLOVE50_new =pd.concat([s4,s0],axis=1)\n",
        "sentence_feature_GLOVE100_new=pd.concat([s5,s0],axis=1)\n",
        "\n",
        "sentence_feature_normal_new  =sentence_feature_normal_new.to_numpy()\n",
        "sentence_feature_tweet_new   =sentence_feature_tweet_new.to_numpy()\n",
        "sentence_feature_GLOVE_new   =sentence_feature_GLOVE_new.to_numpy()\n",
        "sentence_feature_GLOVE25_new =sentence_feature_GLOVE25_new.to_numpy()\n",
        "sentence_feature_GLOVE50_new =sentence_feature_GLOVE50_new.to_numpy()\n",
        "sentence_feature_GLOVE100_new=sentence_feature_GLOVE100_new.to_numpy()\n",
        "\n",
        "sentence_feature_GLOVE.shape"
      ],
      "metadata": {
        "id": "4Qd7Zcgz972G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "724dc537-4f87-41c0-ec06-750cf2cd4447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6425, 44)"
            ]
          },
          "metadata": {},
          "execution_count": 444
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reps_dict={\n",
        "    \"BERT_pca\":sentence_feature_normal,\n",
        "    \"tweetBERT_pca\":sentence_feature_tweet,\n",
        "    \"GLOVE_pca\":sentence_feature_GLOVE,\n",
        "    \"GLOVE50_pca\":sentence_feature_GLOVE25,\n",
        "    \"GLOVE25_pca\":sentence_feature_GLOVE50,\n",
        "    \"GLOVE100_pca\":sentence_feature_GLOVE100,\n",
        "    \"BERT_pca_concat\":sentence_feature_normal_new,\n",
        "    \"tweetBERT_pca_concat\":sentence_feature_tweet_new,\n",
        "    \"GLOVE_pca_concat\":sentence_feature_GLOVE_new,\n",
        "    \"GLOVE50_pca_concat\":sentence_feature_GLOVE25_new,\n",
        "    \"GLOVE25_pca_concat\":sentence_feature_GLOVE50_new,\n",
        "    \"GLOVE100_pca_concat\":sentence_feature_GLOVE100_new,\n",
        "}"
      ],
      "metadata": {
        "id": "X34iBzQ-903X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Settings\n",
        "### AL_loop()"
      ],
      "metadata": {
        "id": "shuUzqwXGK9s"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpJKSPedcge3"
      },
      "source": [
        "number_of_run = 1\n",
        "\n",
        "def AL_loop(rep, model, AL_stg):\n",
        "\n",
        "  sentence_feature=reps_dict[rep]\n",
        "  data_test=sentence_feature[train_start:train_end + 1]\n",
        "  strat = uncertainty_sampling\n",
        "\n",
        "  if AL_stg==\"lc\": stg=False\n",
        "\n",
        "\n",
        "  if AL_stg==\"Random\": stg=True\n",
        "\n",
        "\n",
        "  if AL_stg==\"batch_lc\":\n",
        "     stg=False\n",
        "     strat=uncertainty_batch_sampling\n",
        "\n",
        "\n",
        "  if AL_stg==\"qbc\" or AL_stg=='boost' or AL_stg=='bag':\n",
        "     stg=False\n",
        "     print(AL_stg,'   ',rep,'    ',model)\n",
        "     acc_avg, f1_avg, pref_random, pref_hist_majority, N_QUERIES = run_multy_commite(50, data_test, test_labels, number_of_run, model, strat, 20, stg, AL_stg)\n",
        "\n",
        "\n",
        "  if AL_stg==\"epsilon_in_batch\" or AL_stg==\"cross\":\n",
        "     stg=False\n",
        "\n",
        "\n",
        "  if model==\"mlp\":\n",
        "    if rep!= \"GLOVE_pca_concat\":\n",
        "      acc_avg, f1_avg, pref_random, pref_hist_majority, N_QUERIES = run_multy(50, data_test, test_labels, number_of_run, create_keras_model_berts, strat, 20, stg)\n",
        "    else:\n",
        "      acc_avg, f1_avg, pref_random, pref_hist_majority, N_QUERIES = run_multy(50, data_test, test_labels, number_of_run, create_keras_model_GLOVE, strat, 20, stg)\n",
        "\n",
        "\n",
        "  elif AL_stg==\"epsilon_in_batch\":\n",
        "    acc_avg, f1_avg, pref_random, pref_hist_majority, N_QUERIES = run_multy_epsilon_greedy(50, data_test, test_labels, number_of_run,model, strat, 20, False)\n",
        "\n",
        "  elif AL_stg==\"cross\":\n",
        "    acc_avg, f1_avg, pref_random, pref_hist_majority, N_QUERIES = run_multy_cross(50, data_test, test_labels, number_of_run, model, strat, 20, False)\n",
        "\n",
        "  elif AL_stg!=\"qbc\":\n",
        "    acc_avg, f1_avg, pref_random, pref_hist_majority, N_QUERIES = run_multy_sklearn(50, data_test, test_labels, number_of_run, model, strat, 20, stg)\n",
        "\n",
        "\n",
        "\n",
        "  return acc_avg, f1_avg, pref_random, pref_hist_majority, N_QUERIES\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPnwh_r6Wk4C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "908ec2e8-1dc5-474c-9cdd-2a92a8de48ec"
      },
      "source": [
        "representation = \"GLOVE_pca_concat\"\n",
        "model          = \"mlp\"\n",
        "AL_Strategy    = \"lc\"\n",
        "\n",
        "acc, f1, pref_random, pref_hist_majority, N_QUERIES = AL_loop(representation, model, AL_Strategy)\n",
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 20\n",
            "x pool length (20, 50)\n",
            "y pool length (20, 2)\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7155 - accuracy: 0.5000\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "3/3 [==============================] - 1s 7ms/step - loss: 0.7570 - accuracy: 0.3143\n",
            "4/4 [==============================] - 1s 6ms/step - loss: 0.6537 - accuracy: 0.6583\n",
            "6/6 [==============================] - 1s 4ms/step - loss: 0.6834 - accuracy: 0.5529\n",
            "7/7 [==============================] - 1s 6ms/step - loss: 0.6201 - accuracy: 0.7364\n",
            "9/9 [==============================] - 1s 6ms/step - loss: 0.6318 - accuracy: 0.7111\n",
            "sec (979, 2)\n",
            "65/65 [==============================] - 0s 2ms/step\n",
            "33/33 [==============================] - 0s 1ms/step\n",
            "after query 2: Accuracy :0.8196 macro f1 :0.6567\n",
            "31/31 [==============================] - 0s 1ms/step\n",
            "10/10 [==============================] - 1s 5ms/step - loss: 0.6433 - accuracy: 0.6281\n",
            "12/12 [==============================] - 1s 4ms/step - loss: 0.6326 - accuracy: 0.6757\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.6568 - accuracy: 0.6214\n",
            "15/15 [==============================] - 1s 4ms/step - loss: 0.6409 - accuracy: 0.6702\n",
            "17/17 [==============================] - 2s 4ms/step - loss: 0.6601 - accuracy: 0.6096\n",
            "sec (929, 2)\n",
            "65/65 [==============================] - 0s 2ms/step\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 3: Accuracy :0.8292 macro f1 :0.7067\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "18/18 [==============================] - 1s 3ms/step - loss: 0.6657 - accuracy: 0.5509\n",
            "20/20 [==============================] - 1s 5ms/step - loss: 0.6589 - accuracy: 0.6032\n",
            "21/21 [==============================] - 1s 5ms/step - loss: 0.6738 - accuracy: 0.6075\n",
            "23/23 [==============================] - 1s 3ms/step - loss: 0.6453 - accuracy: 0.6583\n",
            "25/25 [==============================] - 1s 3ms/step - loss: 0.6470 - accuracy: 0.6636\n",
            "sec (879, 2)\n",
            "65/65 [==============================] - 0s 2ms/step\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 4: Accuracy :0.8499 macro f1 :0.7551\n",
            "28/28 [==============================] - 0s 2ms/step\n",
            "26/26 [==============================] - 1s 3ms/step - loss: 0.6650 - accuracy: 0.5878\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6560 - accuracy: 0.6172\n",
            "29/29 [==============================] - 1s 3ms/step - loss: 0.6563 - accuracy: 0.6196\n",
            "31/31 [==============================] - 1s 3ms/step - loss: 0.6589 - accuracy: 0.6113\n",
            "32/32 [==============================] - 1s 3ms/step - loss: 0.6540 - accuracy: 0.6039\n",
            "sec (829, 2)\n",
            "65/65 [==============================] - 0s 1ms/step\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 5: Accuracy :0.8413 macro f1 :0.7437\n",
            "26/26 [==============================] - 0s 2ms/step\n",
            "34/34 [==============================] - 1s 3ms/step - loss: 0.6602 - accuracy: 0.6290\n",
            "35/35 [==============================] - 1s 4ms/step - loss: 0.6523 - accuracy: 0.6259\n",
            "37/37 [==============================] - 1s 5ms/step - loss: 0.6509 - accuracy: 0.6282\n",
            "39/39 [==============================] - 1s 3ms/step - loss: 0.6581 - accuracy: 0.5984\n",
            "40/40 [==============================] - 1s 3ms/step - loss: 0.6537 - accuracy: 0.6228\n",
            "sec (779, 2)\n",
            "65/65 [==============================] - 0s 1ms/step\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 6: Accuracy :0.8408 macro f1 :0.7229\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "42/42 [==============================] - 1s 3ms/step - loss: 0.6531 - accuracy: 0.6348\n",
            "43/43 [==============================] - 1s 3ms/step - loss: 0.6530 - accuracy: 0.6175\n",
            "45/45 [==============================] - 1s 3ms/step - loss: 0.6582 - accuracy: 0.6232\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.6500 - accuracy: 0.6245\n",
            "48/48 [==============================] - 1s 3ms/step - loss: 0.6414 - accuracy: 0.6257\n",
            "sec (729, 2)\n",
            "65/65 [==============================] - 0s 2ms/step\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 7: Accuracy :0.8567 macro f1 :0.7596\n",
            "23/23 [==============================] - 0s 2ms/step\n",
            "50/50 [==============================] - 1s 3ms/step - loss: 0.6414 - accuracy: 0.6376\n",
            "51/51 [==============================] - 1s 4ms/step - loss: 0.6409 - accuracy: 0.6475\n",
            "53/53 [==============================] - 1s 3ms/step - loss: 0.6426 - accuracy: 0.6503\n",
            "54/54 [==============================] - 1s 3ms/step - loss: 0.6526 - accuracy: 0.6297\n",
            "56/56 [==============================] - 1s 3ms/step - loss: 0.6355 - accuracy: 0.6525\n",
            "sec (679, 2)\n",
            "65/65 [==============================] - 0s 2ms/step\n",
            "33/33 [==============================] - 0s 1ms/step\n",
            "after query 8: Accuracy :0.8538 macro f1 :0.7391\n",
            "22/22 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 1s 3ms/step - loss: 0.6370 - accuracy: 0.6533\n",
            "59/59 [==============================] - 1s 3ms/step - loss: 0.6294 - accuracy: 0.6572\n",
            "60/60 [==============================] - 1s 3ms/step - loss: 0.6386 - accuracy: 0.6526\n",
            "62/62 [==============================] - 1s 3ms/step - loss: 0.6325 - accuracy: 0.6503\n",
            "64/64 [==============================] - 1s 5ms/step - loss: 0.6299 - accuracy: 0.6589\n",
            "sec (629, 2)\n",
            "65/65 [==============================] - 0s 2ms/step\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 9: Accuracy :0.8595 macro f1 :0.7577\n",
            "20/20 [==============================] - 0s 2ms/step\n",
            "65/65 [==============================] - 2s 5ms/step - loss: 0.6206 - accuracy: 0.6749\n",
            "67/67 [==============================] - 1s 4ms/step - loss: 0.6314 - accuracy: 0.6613\n",
            "68/68 [==============================] - 1s 3ms/step - loss: 0.6161 - accuracy: 0.6677\n",
            "70/70 [==============================] - 1s 3ms/step - loss: 0.6192 - accuracy: 0.6649\n",
            "71/71 [==============================] - 1s 3ms/step - loss: 0.6068 - accuracy: 0.6894\n",
            "sec (579, 2)\n",
            "65/65 [==============================] - 0s 2ms/step\n",
            "33/33 [==============================] - 0s 1ms/step\n",
            "after query 10: Accuracy :0.8581 macro f1 :0.7535\n",
            "19/19 [==============================] - 0s 2ms/step\n",
            "73/73 [==============================] - 1s 3ms/step - loss: 0.6189 - accuracy: 0.6569\n",
            "75/75 [==============================] - 1s 3ms/step - loss: 0.6029 - accuracy: 0.6852\n",
            "76/76 [==============================] - 1s 3ms/step - loss: 0.6030 - accuracy: 0.6740\n",
            "78/78 [==============================] - 1s 5ms/step - loss: 0.6091 - accuracy: 0.6652\n",
            "79/79 [==============================] - 2s 5ms/step - loss: 0.5811 - accuracy: 0.6976\n",
            "sec (529, 2)\n",
            "65/65 [==============================] - 0s 2ms/step\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 11: Accuracy :0.8543 macro f1 :0.7372\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "81/81 [==============================] - 3s 4ms/step - loss: 0.5846 - accuracy: 0.6930\n",
            "82/82 [==============================] - 2s 3ms/step - loss: 0.5751 - accuracy: 0.6969\n",
            "84/84 [==============================] - 1s 3ms/step - loss: 0.5829 - accuracy: 0.6831\n",
            "85/85 [==============================] - 1s 3ms/step - loss: 0.5655 - accuracy: 0.7125\n",
            "87/87 [==============================] - 1s 3ms/step - loss: 0.5733 - accuracy: 0.6957\n",
            "sec (479, 2)\n",
            "65/65 [==============================] - 0s 1ms/step\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 12: Accuracy :0.8547 macro f1 :0.7433\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "89/89 [==============================] - 1s 3ms/step - loss: 0.5733 - accuracy: 0.6933\n",
            "90/90 [==============================] - 1s 4ms/step - loss: 0.5623 - accuracy: 0.7125\n",
            "92/92 [==============================] - 2s 5ms/step - loss: 0.5503 - accuracy: 0.7120\n",
            "93/93 [==============================] - 1s 3ms/step - loss: 0.5429 - accuracy: 0.7276\n",
            "95/95 [==============================] - 1s 3ms/step - loss: 0.5531 - accuracy: 0.7043\n",
            "sec (429, 2)\n",
            "65/65 [==============================] - 0s 2ms/step\n",
            "33/33 [==============================] - 0s 1ms/step\n",
            "after query 13: Accuracy :0.8552 macro f1 :0.7523\n",
            "14/14 [==============================] - 0s 1ms/step\n",
            "96/96 [==============================] - 1s 3ms/step - loss: 0.5518 - accuracy: 0.7029\n",
            "98/98 [==============================] - 1s 3ms/step - loss: 0.5353 - accuracy: 0.7247\n",
            "100/100 [==============================] - 2s 3ms/step - loss: 0.5200 - accuracy: 0.7293\n",
            "101/101 [==============================] - 1s 3ms/step - loss: 0.5361 - accuracy: 0.7202\n",
            "103/103 [==============================] - 2s 5ms/step - loss: 0.5224 - accuracy: 0.7278\n",
            "sec (379, 2)\n",
            "65/65 [==============================] - 0s 2ms/step\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 14: Accuracy :0.8567 macro f1 :0.7479\n",
            "12/12 [==============================] - 0s 3ms/step\n",
            "104/104 [==============================] - 2s 3ms/step - loss: 0.5180 - accuracy: 0.7349\n",
            "106/106 [==============================] - 1s 3ms/step - loss: 0.5006 - accuracy: 0.7481\n",
            "107/107 [==============================] - 1s 3ms/step - loss: 0.5030 - accuracy: 0.7459\n",
            "109/109 [==============================] - 1s 3ms/step - loss: 0.5038 - accuracy: 0.7473\n",
            "110/110 [==============================] - 1s 3ms/step - loss: 0.5036 - accuracy: 0.7423\n",
            "sec (329, 2)\n",
            "65/65 [==============================] - 0s 1ms/step\n",
            "33/33 [==============================] - 0s 1ms/step\n",
            "after query 15: Accuracy :0.8504 macro f1 :0.7352\n",
            "11/11 [==============================] - 0s 2ms/step\n",
            "112/112 [==============================] - 1s 3ms/step - loss: 0.4835 - accuracy: 0.7678\n",
            "114/114 [==============================] - 1s 3ms/step - loss: 0.4833 - accuracy: 0.7517\n",
            "115/115 [==============================] - 2s 5ms/step - loss: 0.4754 - accuracy: 0.7689\n",
            "117/117 [==============================] - 2s 3ms/step - loss: 0.4664 - accuracy: 0.7661\n",
            "118/118 [==============================] - 1s 3ms/step - loss: 0.4692 - accuracy: 0.7663\n",
            "sec (279, 2)\n",
            "65/65 [==============================] - 0s 2ms/step\n",
            "33/33 [==============================] - 0s 1ms/step\n",
            "after query 16: Accuracy :0.8509 macro f1 :0.7364\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "120/120 [==============================] - 1s 3ms/step - loss: 0.4733 - accuracy: 0.7576\n",
            "121/121 [==============================] - 1s 3ms/step - loss: 0.4742 - accuracy: 0.7550\n",
            "123/123 [==============================] - 1s 3ms/step - loss: 0.4444 - accuracy: 0.7849\n",
            "125/125 [==============================] - 1s 3ms/step - loss: 0.4445 - accuracy: 0.7889\n",
            "126/126 [==============================] - 1s 3ms/step - loss: 0.4459 - accuracy: 0.7818\n",
            "sec (229, 2)\n",
            "65/65 [==============================] - 0s 2ms/step\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 17: Accuracy :0.8538 macro f1 :0.7518\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 2s 5ms/step - loss: 0.4428 - accuracy: 0.7771\n",
            "129/129 [==============================] - 2s 3ms/step - loss: 0.4220 - accuracy: 0.7942\n",
            "131/131 [==============================] - 1s 3ms/step - loss: 0.4418 - accuracy: 0.7825\n",
            "132/132 [==============================] - 1s 3ms/step - loss: 0.4273 - accuracy: 0.7934\n",
            "134/134 [==============================] - 1s 3ms/step - loss: 0.4109 - accuracy: 0.8042\n",
            "sec (179, 2)\n",
            "65/65 [==============================] - 0s 1ms/step\n",
            "33/33 [==============================] - 0s 1ms/step\n",
            "after query 18: Accuracy :0.8552 macro f1 :0.7491\n",
            "6/6 [==============================] - 0s 2ms/step\n",
            "135/135 [==============================] - 1s 3ms/step - loss: 0.4250 - accuracy: 0.7859\n",
            "137/137 [==============================] - 1s 3ms/step - loss: 0.4034 - accuracy: 0.8110\n",
            "139/139 [==============================] - 1s 3ms/step - loss: 0.4100 - accuracy: 0.8000\n",
            "140/140 [==============================] - 2s 5ms/step - loss: 0.3958 - accuracy: 0.8128\n",
            "142/142 [==============================] - 2s 3ms/step - loss: 0.3928 - accuracy: 0.8144\n",
            "sec (129, 2)\n",
            "65/65 [==============================] - 0s 2ms/step\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 19: Accuracy :0.8571 macro f1 :0.7518\n",
            "5/5 [==============================] - 0s 2ms/step\n",
            "143/143 [==============================] - 1s 3ms/step - loss: 0.3972 - accuracy: 0.8129\n",
            "145/145 [==============================] - 1s 3ms/step - loss: 0.3998 - accuracy: 0.8115\n",
            "146/146 [==============================] - 1s 3ms/step - loss: 0.3872 - accuracy: 0.8135\n",
            "148/148 [==============================] - 2s 5ms/step - loss: 0.3826 - accuracy: 0.8189\n",
            "150/150 [==============================] - 2s 5ms/step - loss: 0.3891 - accuracy: 0.8103\n",
            "sec (79, 2)\n",
            "65/65 [==============================] - 0s 2ms/step\n",
            "33/33 [==============================] - 0s 3ms/step\n",
            "after query 20: Accuracy :0.8600 macro f1 :0.7577\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "151/151 [==============================] - 1s 3ms/step - loss: 0.3708 - accuracy: 0.8247\n",
            "153/153 [==============================] - 1s 3ms/step - loss: 0.3710 - accuracy: 0.8265\n",
            "154/154 [==============================] - 1s 3ms/step - loss: 0.3714 - accuracy: 0.8248\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.3789 - accuracy: 0.8215\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 0.3628 - accuracy: 0.8267\n",
            "sec (29, 2)\n",
            "65/65 [==============================] - 0s 1ms/step\n",
            "33/33 [==============================] - 0s 1ms/step\n",
            "after query 21: Accuracy :0.8538 macro f1 :0.7433\n",
            "0:02:44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnVxfd3syJBN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64e83e8f-ffa2-44a4-a7b8-d99718b3ceb3"
      },
      "source": [
        "# acc_25perc_avg=acc[:,:int(0.25*N_QUERIES)].mean(0)\n",
        "# f1_25perc_avg=f1[:,:int(0.25*N_QUERIES)].mean(0)\n",
        "\n",
        "# print(acc_25perc_avg[-1])\n",
        "# print(f1_25perc_avg[-1])\n",
        "\n",
        "\n",
        "acc_25perc_avg=acc[:int(0.25*N_QUERIES)].mean(0)\n",
        "f1_25perc_avg=f1[:int(0.25*N_QUERIES)].mean(0)\n",
        "\n",
        "print(acc_25perc_avg)\n",
        "print(f1_25perc_avg)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6680134680134681\n",
            "0.6696482184128798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For Fine_Tuning\n"
      ],
      "metadata": {
        "id": "T_5DIrR4sEV-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCOpzX96IsrG"
      },
      "source": [
        "# topic_num=0\n",
        "# test_df=data[data['topic']==topic_num]\n",
        "# train_df=data[data['topic']!=topic_num]\n",
        "# train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqvHai1elpta"
      },
      "source": [
        "# data2=data.reset_index()\n",
        "# start_test=data2[data2['topic']==topic_num].iloc[0]\n",
        "# def pd_iter_func(df,topic):\n",
        "    # for row in df.itertuples():\n",
        "        ## Define your criteria here\n",
        "        # if row.topic==topic:\n",
        "            # return row\n",
        "\n",
        "# start_test=pd_iter_func(data2, 1).Index\n",
        "# end_test=pd_iter_func(data2, 2).Index-1\n",
        "# train_start=pd_iter_func(data2, topic_num).Index\n",
        "# train_end=len(data2)\n",
        "\n",
        "# print(start_test,',', end_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hcvb0IhoJ07V"
      },
      "source": [
        "# train_sentences=train_df.text.values\n",
        "# test_sentences=test_df.text.values\n",
        "# train_labels=train_df.tag.values\n",
        "# test_labels=test_df.tag.values\n",
        "# len(train_labels)\n",
        "\n",
        "# train_sentences.shape\n",
        "\n",
        "\n",
        "# test_labels=test_df.tag.values\n",
        "# train_start=0\n",
        "# train_end=2078"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-esnaFdhBBS"
      },
      "source": [
        "### Word Representation\n",
        "#### BERT Representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgSfeIiaoeFJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc018d95-9f79-41c4-ae7a-c93f473b99f7"
      },
      "source": [
        "!pip install emoji"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.9/dist-packages (2.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oQ61gE0pnZL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "980f8302-3e37-4bf8-f252-b0b9be5f9f75"
      },
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "bert_tweet = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\n",
        "tokenizer_tweet = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j1z0rI5FNVL"
      },
      "source": [
        "def tokenizer_func(tokenizer_kind, sentences, labels):\n",
        "  '''\n",
        "  inputs:\n",
        "    tokenizer_kind: is the the tokenizer of choice (normal bert, tweet bert)\n",
        "    sentences: train , dev, test\n",
        "  outputs:\n",
        "  torchs of\n",
        "    ids\n",
        "    attention_mask\n",
        "    labels\n",
        "  '''\n",
        "  input_ids=[]\n",
        "  attention_masks=[]\n",
        "\n",
        "  # For every sentence...\n",
        "  for sent in sentences:\n",
        "      # `encode_plus` will:\n",
        "      #   (1) Tokenize the sentence.\n",
        "      #   (2) Prepend the `[CLS]` token to the start.\n",
        "      #   (3) Append the `[SEP]` token to the end.\n",
        "      #   (4) Map tokens to their IDs.\n",
        "      #   (5) Pad or truncate the sentence to `max_length`\n",
        "      #   (6) Create attention masks for [PAD] tokens.\n",
        "      encoded_dict=tokenizer_kind.encode_plus(\n",
        "                          sent,                       # Sentence to encode.\n",
        "                          add_special_tokens=True,    # Add '[CLS]' and '[SEP]'\n",
        "                          max_length=128,             # Pad & truncate all sentences.\n",
        "                          pad_to_max_length=True,\n",
        "                          return_attention_mask=True, # Construct attn. masks.\n",
        "                          return_tensors='pt',        # Return pytorch tensors.\n",
        "                          truncation=True,\n",
        "                    )\n",
        "\n",
        "      # Add the encoded sentence to the list.\n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "      # And its attention mask (simply differentiates padding from non-padding).\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  # Convert the lists into tensors.\n",
        "  input_ids=torch.cat(input_ids, dim=0)\n",
        "  attention_masks=torch.cat(attention_masks, dim=0)\n",
        "  labels=torch.tensor(labels)\n",
        "\n",
        "  return input_ids, attention_masks, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PO4WiaOFU01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b009c40-bb05-4bdb-e602-c1acc58940b3"
      },
      "source": [
        "sentences=data.text.values\n",
        "train_labels=data.tag.values\n",
        "input_ids, attention_masks, labels=tokenizer_func(tokenizer_tweet, sentences, train_labels)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train_valid_split()"
      ],
      "metadata": {
        "id": "xFIfGhCqcTJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_valid_split(input_ids, attention_masks, labels, batch_size=128):\n",
        "\n",
        "    # Use 70% for training and 30% for validation.\n",
        "    train_inputs, validation_inputs,  train_masks, validation_masks, train_labels, validation_labels = train_test_split(\n",
        "        input_ids, attention_masks, labels, random_state=32, test_size=0.3, stratify=labels)\n",
        "\n",
        "    print('example train_input:    ', train_inputs[0])\n",
        "    print('example attention_mask: ', train_masks[0])\n",
        "\n",
        "    train_labels=torch.tensor(train_labels)\n",
        "    validation_labels=torch.tensor(validation_labels)\n",
        "\n",
        "    # Create the DataLoader for our training set.\n",
        "    train_data=TensorDataset(train_inputs, train_masks, train_labels)\n",
        "    train_dataloader=DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "    # Create the DataLoader for our validation set.\n",
        "    validation_data=TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "    validation_dataloader=DataLoader(validation_data, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "    return train_dataloader, validation_dataloader"
      ],
      "metadata": {
        "id": "AnBra9yo4ryN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYB5FSknIx_u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa02d1db-46ed-4590-f6f8-4d6073576bf8"
      },
      "source": [
        "bert_train_dataloader, bert_validation_dataloader = train_valid_split(\n",
        "    input_ids=input_ids,\n",
        "    attention_masks=attention_masks,\n",
        "    labels=labels,\n",
        "    batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "example train_input:     tensor([  101, 16098,  2021,  1138,  1208,  3626,  1103, 14551,  1321,  1197,\n",
            "         1120,   108,  3122,  1708,  1663,  2176,   119,  4222, 21832,  1138,\n",
            "         5742,   117,  1405,  1234,  1132,  2475,  1253,  1217,  1316,   119,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n",
            "example attention_mask:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-458-cb6252b0985e>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_labels=torch.tensor(train_labels)\n",
            "<ipython-input-458-cb6252b0985e>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  validation_labels=torch.tensor(validation_labels)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data"
      ],
      "metadata": {
        "id": "3Z-742dkb3a2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "5zY5jG1nnLCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_feature_normal=np.load('normal_bert.npy')\n",
        "X_pretrain=sentence_feature_normal[train_start:train_end + 1]\n",
        "X_pretrain.shape\n",
        "\n",
        "y_pretrain=test_labels\n",
        "y_pretrain.shape"
      ],
      "metadata": {
        "id": "61FKGJjR7aKE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e80b558a-8256-4b2a-a057-cb1cc3e91bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2079,)"
            ]
          },
          "metadata": {},
          "execution_count": 461
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_pretrain.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHM4GC30hFka",
        "outputId": "52ebf586-dc9a-48ac-d225-8658442ad358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "metadata": {},
          "execution_count": 462
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2Fj84q7wSpM",
        "outputId": "e12ce47c-0614-4803-e897-b31da5b5d48c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('int64')"
            ]
          },
          "metadata": {},
          "execution_count": 463
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define and Pre-train the Model"
      ],
      "metadata": {
        "id": "RfUESJ9Za287"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from modAL.models import ActiveLearner\n",
        "import keras\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "gt15k2v1a9xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_pretrain=np.random.randn(1000,768)\n",
        "# y_pretrain=np.random.randint(2,size=(1000,))\n",
        "y_pretrain_categorical=keras.utils.to_categorical(y_pretrain , 2)\n",
        "\n",
        "print(\"Define and Pre-train a model\")\n",
        "def create_keras_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(768, activation='relu'))\n",
        "    model.add(Dense(300, activation='relu'))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    history = model.fit(X_pretrain , y_pretrain_categorical, verbose=1, epochs=15)\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = True\n",
        "    for layer in model.layers[:-2]:\n",
        "        layer.trainable = False\n",
        "    return model\n",
        "\n",
        "classifier = KerasClassifier(create_keras_model)"
      ],
      "metadata": {
        "id": "nlbRLPXVUVlb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bec0b3f-db5a-4a9d-d457-1f11a0d98016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Define and Pre-train a model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-465-1722700fcbdd>:21: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  classifier = KerasClassifier(create_keras_model)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test ActiveLearner on the Model and a different Dataset"
      ],
      "metadata": {
        "id": "Ykedbdm-bKlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_2 = np.random.randn(500,768)\n",
        "# y_2 = np.random.randint(2,size=(500,))\n",
        "# y_2_categorical = keras.utils.to_categorical(y_2, 2)\n",
        "# print(\"ActiveLearner\")\n",
        "# learner = ActiveLearner(\n",
        "#     estimator=classifier,\n",
        "#     X_training=X_2, y_training=y_2_categorical,\n",
        "#     verbose=1)"
      ],
      "metadata": {
        "id": "HVB_ujBhbEe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_feature_tweet=np.load('tweet_bert.npy')\n",
        "data_test=sentence_feature_tweet[train_start:train_end + 1]\n",
        "\n",
        "data_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4a2-Yn5gfQi",
        "outputId": "a690b132-c738-4c87-82b3-117b6906fff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2079, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 467
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZ-aJxvlgzH4",
        "outputId": "397f4e5c-e042-45f4-899c-483697699a86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2079,)"
            ]
          },
          "metadata": {},
          "execution_count": 468
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE, num_of_run, strategy, is_random = 50, 1, uncertainty_sampling, False\n",
        "\n",
        "test_pool_split=0.5\n",
        "preset_batch=partial(strategy, n_instances=BATCH_SIZE)\n",
        "X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(data_test, test_labels, test_size=20, shuffle=True)\n",
        "X_pool_0, X_test_0, y_pool_0, y_test_0 = train_test_split(X_pool_0, y_pool_0, test_size=test_pool_split, shuffle=True)\n",
        "\n",
        "N_QUERIES=int(len(X_pool_0)/BATCH_SIZE)\n",
        "\n",
        "pref_hist_multy_accuracy=np.zeros((num_of_run, N_QUERIES+1))\n",
        "pref_hist_multy_f1=np.zeros((num_of_run, N_QUERIES+1))\n",
        "pref_random=0\n",
        "\n",
        "# test_labels=keras.utils.to_categorical(test_labels, 2)\n",
        "\n",
        "for i in range(num_of_run):\n",
        "  X_pool, X_train, y_pool, y_train = train_test_split(data_test, test_labels, test_size=20, shuffle=True, random_state=random_seed_list[i])\n",
        "  X_pool, X_test, y_pool, y_test = train_test_split(X_pool, y_pool, test_size=test_pool_split, shuffle=True, random_state=random_seed_list[i])\n",
        "\n",
        "  # y_train_categorical = keras.utils.to_categorical(y_train, 2)\n",
        "  # y_test_cat = keras.utils.to_categorical(y_test, 2)\n",
        "  # y_pool_cat = keras.utils.to_categorical(y_pool, 2)\n",
        "\n",
        "  clf = classifier\n",
        "\n",
        "  # clf = KerasClassifier(model)\n",
        "\n",
        "  print('x pool length', X_train.shape)\n",
        "  print('y pool length', y_train.shape)\n",
        "\n",
        "  learner = ActiveLearner(\n",
        "      estimator=clf,\n",
        "      query_strategy=preset_batch,\n",
        "      X_training=X_train,\n",
        "      y_training=y_train)\n",
        "\n",
        "\n",
        "  t1 = time.time()\n",
        "\n",
        "  # Calculate initial batch\n",
        "  y_pred=learner.predict(X_test)\n",
        "  # y_test_cat=np.argmax(y_test,axis=1)\n",
        "  macro=f1_score(y_test, y_pred, average='macro')\n",
        "  pref_hist_multy_f1[i][0]=macro\n",
        "\n",
        "\n",
        "  for index in range(1,N_QUERIES+1):\n",
        "    query_index, query_instance=learner.query(X_pool)\n",
        "\n",
        "    # indices=[i for i, val in enumerate(y_pool) if val >= len(y_pool)]\n",
        "    # query_index, query_instance = np.delete(query_index, indices, axis=0), np.delete(query_instance, indices,axis=0)\n",
        "    # print('num if query',len(query_index))\n",
        "\n",
        "    if is_random:\n",
        "      index_list=range(len(X_pool))\n",
        "      query_index=random.sample(index_list,BATCH_SIZE)\n",
        "\n",
        "    # Teach our ActiveLearner model the record it has requested.\n",
        "    X, y = X_pool[query_index], y_pool[query_index]\n",
        "\n",
        "    for j in range(1):\n",
        "      learner.teach(X=X, y=y)\n",
        "\n",
        "      # Remove the queried instance from the unlabeled pool.\n",
        "      X_pool, y_pool = np.delete(X_pool, query_index, axis=0), np.delete(y_pool, query_index,axis=0)\n",
        "      print('sec',y_pool.shape)\n",
        "\n",
        "      # Calculate and report our model's accuracy.\n",
        "      model_accuracy=learner.score(data_test, test_labels)\n",
        "      y_pred=learner.predict(X_test)\n",
        "      # y_test_cat=np.argmax(y_test, axis=1)\n",
        "      # print('shapeè',y_test_cat.shape)\n",
        "      macro=f1_score(y_test, y_pred, average='macro')\n",
        "      print('after query {n}: Accuracy :{acc:0.4f} macro f1 :{f1:0.4f}'.format(n=index + 1, acc=model_accuracy, f1=macro))\n",
        "\n",
        "      # Save our model's performance for plotting.\n",
        "      pref_hist_multy_accuracy[i][index]=model_accuracy\n",
        "      pref_hist_multy_f1[i][index]=macro\n",
        "\n",
        "  pref_hist_multy_acc_avg=pref_hist_multy_accuracy.mean(0)\n",
        "  pref_hist_multy_f1_avg=pref_hist_multy_f1.mean(0)\n",
        ""
      ],
      "metadata": {
        "id": "vVVqTCQksJPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9898100f-f8da-4c6a-aa0d-9b376e55e482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x pool length (20, 768)\n",
            "y pool length (20,)\n",
            "Epoch 1/15\n",
            "65/65 [==============================] - 3s 5ms/step - loss: 0.4195 - accuracy: 0.8090\n",
            "Epoch 2/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3242 - accuracy: 0.8485\n",
            "Epoch 3/15\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.2834 - accuracy: 0.8639\n",
            "Epoch 4/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2573 - accuracy: 0.8793\n",
            "Epoch 5/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2626 - accuracy: 0.8721\n",
            "Epoch 6/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2317 - accuracy: 0.8874\n",
            "Epoch 7/15\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.2249 - accuracy: 0.8908\n",
            "Epoch 8/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2160 - accuracy: 0.9043\n",
            "Epoch 9/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1891 - accuracy: 0.9144\n",
            "Epoch 10/15\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1862 - accuracy: 0.9226\n",
            "Epoch 11/15\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1650 - accuracy: 0.9293\n",
            "Epoch 12/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1592 - accuracy: 0.9331\n",
            "Epoch 13/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1393 - accuracy: 0.9423\n",
            "Epoch 14/15\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1281 - accuracy: 0.9447\n",
            "Epoch 15/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1110 - accuracy: 0.9562\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7010 - accuracy: 0.7500\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "Epoch 1/15\n",
            "65/65 [==============================] - 2s 4ms/step - loss: 0.3884 - accuracy: 0.8028\n",
            "Epoch 2/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3065 - accuracy: 0.8393\n",
            "Epoch 3/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2732 - accuracy: 0.8610\n",
            "Epoch 4/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2488 - accuracy: 0.8826\n",
            "Epoch 5/15\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.2610 - accuracy: 0.8793\n",
            "Epoch 6/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2377 - accuracy: 0.8822\n",
            "Epoch 7/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2295 - accuracy: 0.8879\n",
            "Epoch 8/15\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.2100 - accuracy: 0.9096\n",
            "Epoch 9/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2106 - accuracy: 0.9038\n",
            "Epoch 10/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1879 - accuracy: 0.9125\n",
            "Epoch 11/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1603 - accuracy: 0.9293\n",
            "Epoch 12/15\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1565 - accuracy: 0.9269\n",
            "Epoch 13/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1424 - accuracy: 0.9389\n",
            "Epoch 14/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1522 - accuracy: 0.9336\n",
            "Epoch 15/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1330 - accuracy: 0.9500\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.4392 - accuracy: 0.4714\n",
            "sec (979,)\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.7168 - accuracy: 0.2867\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 2: Accuracy :0.2867 macro f1 :0.2771\n",
            "31/31 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n",
            "65/65 [==============================] - 3s 4ms/step - loss: 0.4136 - accuracy: 0.7932\n",
            "Epoch 2/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3190 - accuracy: 0.8360\n",
            "Epoch 3/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3027 - accuracy: 0.8581\n",
            "Epoch 4/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2909 - accuracy: 0.8504\n",
            "Epoch 5/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2957 - accuracy: 0.8543\n",
            "Epoch 6/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2686 - accuracy: 0.8677\n",
            "Epoch 7/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2551 - accuracy: 0.8749\n",
            "Epoch 8/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2317 - accuracy: 0.8817\n",
            "Epoch 9/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2293 - accuracy: 0.8947\n",
            "Epoch 10/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2106 - accuracy: 0.9014\n",
            "Epoch 11/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2071 - accuracy: 0.8937\n",
            "Epoch 12/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1996 - accuracy: 0.9129\n",
            "Epoch 13/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1928 - accuracy: 0.9110\n",
            "Epoch 14/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1736 - accuracy: 0.9240\n",
            "Epoch 15/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1669 - accuracy: 0.9240\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9062 - accuracy: 0.5833\n",
            "sec (929,)\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7797\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 3: Accuracy :0.7797 macro f1 :0.4381\n",
            "30/30 [==============================] - 0s 2ms/step\n",
            "Epoch 1/15\n",
            "65/65 [==============================] - 2s 4ms/step - loss: 0.4030 - accuracy: 0.8215\n",
            "Epoch 2/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3063 - accuracy: 0.8519\n",
            "Epoch 3/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2801 - accuracy: 0.8620\n",
            "Epoch 4/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2654 - accuracy: 0.8692\n",
            "Epoch 5/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2656 - accuracy: 0.8773\n",
            "Epoch 6/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2383 - accuracy: 0.8850\n",
            "Epoch 7/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2312 - accuracy: 0.8889\n",
            "Epoch 8/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2233 - accuracy: 0.8956\n",
            "Epoch 9/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2030 - accuracy: 0.9028\n",
            "Epoch 10/15\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.1758 - accuracy: 0.9235\n",
            "Epoch 11/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1719 - accuracy: 0.9221\n",
            "Epoch 12/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1700 - accuracy: 0.9221\n",
            "Epoch 13/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1478 - accuracy: 0.9331\n",
            "Epoch 14/15\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.1460 - accuracy: 0.9317\n",
            "Epoch 15/15\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.1417 - accuracy: 0.9456\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.7551 - accuracy: 0.6647\n",
            "sec (879,)\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6898 - accuracy: 0.7797\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 4: Accuracy :0.7797 macro f1 :0.4381\n",
            "28/28 [==============================] - 0s 2ms/step\n",
            "Epoch 1/15\n",
            "65/65 [==============================] - 2s 4ms/step - loss: 0.3967 - accuracy: 0.8018\n",
            "Epoch 2/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3163 - accuracy: 0.8398\n",
            "Epoch 3/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2914 - accuracy: 0.8581\n",
            "Epoch 4/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3047 - accuracy: 0.8480\n",
            "Epoch 5/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2886 - accuracy: 0.8538\n",
            "Epoch 6/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2569 - accuracy: 0.8711\n",
            "Epoch 7/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2515 - accuracy: 0.8764\n",
            "Epoch 8/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2322 - accuracy: 0.8802\n",
            "Epoch 9/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2292 - accuracy: 0.8874\n",
            "Epoch 10/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2068 - accuracy: 0.8985\n",
            "Epoch 11/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1980 - accuracy: 0.9043\n",
            "Epoch 12/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1989 - accuracy: 0.9052\n",
            "Epoch 13/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1800 - accuracy: 0.9144\n",
            "Epoch 14/15\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.1756 - accuracy: 0.9192\n",
            "Epoch 15/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1746 - accuracy: 0.9202\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.7071 - accuracy: 0.6864\n",
            "sec (829,)\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.7797\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 5: Accuracy :0.7797 macro f1 :0.4381\n",
            "26/26 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n",
            "65/65 [==============================] - 2s 4ms/step - loss: 0.3931 - accuracy: 0.8235\n",
            "Epoch 2/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2998 - accuracy: 0.8591\n",
            "Epoch 3/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2664 - accuracy: 0.8672\n",
            "Epoch 4/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2409 - accuracy: 0.8850\n",
            "Epoch 5/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2594 - accuracy: 0.8725\n",
            "Epoch 6/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2213 - accuracy: 0.8850\n",
            "Epoch 7/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2188 - accuracy: 0.9014\n",
            "Epoch 8/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1953 - accuracy: 0.9153\n",
            "Epoch 9/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1917 - accuracy: 0.9153\n",
            "Epoch 10/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1714 - accuracy: 0.9274\n",
            "Epoch 11/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1533 - accuracy: 0.9298\n",
            "Epoch 12/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1555 - accuracy: 0.9322\n",
            "Epoch 13/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1407 - accuracy: 0.9404\n",
            "Epoch 14/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1289 - accuracy: 0.9408\n",
            "Epoch 15/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1264 - accuracy: 0.9485\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.8408 - accuracy: 0.5852\n",
            "sec (779,)\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6815 - accuracy: 0.7797\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 6: Accuracy :0.7797 macro f1 :0.4381\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 1/15\n",
            "65/65 [==============================] - 2s 4ms/step - loss: 0.3991 - accuracy: 0.8057\n",
            "Epoch 2/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3162 - accuracy: 0.8562\n",
            "Epoch 3/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2941 - accuracy: 0.8595\n",
            "Epoch 4/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2885 - accuracy: 0.8586\n",
            "Epoch 5/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2751 - accuracy: 0.8658\n",
            "Epoch 6/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2680 - accuracy: 0.8701\n",
            "Epoch 7/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2506 - accuracy: 0.8764\n",
            "Epoch 8/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2302 - accuracy: 0.8855\n",
            "Epoch 9/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.2240 - accuracy: 0.8985\n",
            "Epoch 10/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1995 - accuracy: 0.9024\n",
            "Epoch 11/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1924 - accuracy: 0.9091\n",
            "Epoch 12/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1799 - accuracy: 0.9187\n",
            "Epoch 13/15\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.1770 - accuracy: 0.9173\n",
            "Epoch 14/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1572 - accuracy: 0.9317\n",
            "Epoch 15/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1370 - accuracy: 0.9384\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7709 - accuracy: 0.6812\n",
            "sec (729,)\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5577 - accuracy: 0.7797\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 7: Accuracy :0.7797 macro f1 :0.4381\n",
            "23/23 [==============================] - 0s 2ms/step\n",
            "Epoch 1/15\n",
            "65/65 [==============================] - 2s 4ms/step - loss: 0.3918 - accuracy: 0.8244\n",
            "Epoch 2/15\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3152 - accuracy: 0.8446\n",
            "Epoch 3/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2730 - accuracy: 0.8634\n",
            "Epoch 4/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2417 - accuracy: 0.8918\n",
            "Epoch 5/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2622 - accuracy: 0.8706\n",
            "Epoch 6/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2222 - accuracy: 0.8918\n",
            "Epoch 7/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2218 - accuracy: 0.8913\n",
            "Epoch 8/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2055 - accuracy: 0.9014\n",
            "Epoch 9/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1834 - accuracy: 0.9177\n",
            "Epoch 10/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1760 - accuracy: 0.9202\n",
            "Epoch 11/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1632 - accuracy: 0.9293\n",
            "Epoch 12/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1453 - accuracy: 0.9307\n",
            "Epoch 13/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1339 - accuracy: 0.9428\n",
            "Epoch 14/15\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.1332 - accuracy: 0.9485\n",
            "Epoch 15/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1488 - accuracy: 0.9375\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8764 - accuracy: 0.5946\n",
            "sec (679,)\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.6883 - accuracy: 0.7797\n",
            "33/33 [==============================] - 0s 3ms/step\n",
            "after query 8: Accuracy :0.7797 macro f1 :0.4381\n",
            "22/22 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n",
            "65/65 [==============================] - 2s 4ms/step - loss: 0.3976 - accuracy: 0.8191\n",
            "Epoch 2/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3071 - accuracy: 0.8475\n",
            "Epoch 3/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2759 - accuracy: 0.8682\n",
            "Epoch 4/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2641 - accuracy: 0.8701\n",
            "Epoch 5/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2783 - accuracy: 0.8639\n",
            "Epoch 6/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2593 - accuracy: 0.8745\n",
            "Epoch 7/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2387 - accuracy: 0.8874\n",
            "Epoch 8/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2226 - accuracy: 0.9000\n",
            "Epoch 9/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2136 - accuracy: 0.8980\n",
            "Epoch 10/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2105 - accuracy: 0.9019\n",
            "Epoch 11/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1869 - accuracy: 0.9168\n",
            "Epoch 12/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1741 - accuracy: 0.9216\n",
            "Epoch 13/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1678 - accuracy: 0.9221\n",
            "Epoch 14/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1503 - accuracy: 0.9317\n",
            "Epoch 15/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1441 - accuracy: 0.9389\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.7170 - accuracy: 0.5810\n",
            "sec (629,)\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.7917\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 9: Accuracy :0.7917 macro f1 :0.5026\n",
            "20/20 [==============================] - 0s 2ms/step\n",
            "Epoch 1/15\n",
            "65/65 [==============================] - 2s 4ms/step - loss: 0.3829 - accuracy: 0.8297\n",
            "Epoch 2/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2943 - accuracy: 0.8600\n",
            "Epoch 3/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2660 - accuracy: 0.8653\n",
            "Epoch 4/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2365 - accuracy: 0.8913\n",
            "Epoch 5/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2646 - accuracy: 0.8696\n",
            "Epoch 6/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2268 - accuracy: 0.8860\n",
            "Epoch 7/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2204 - accuracy: 0.8932\n",
            "Epoch 8/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2089 - accuracy: 0.9091\n",
            "Epoch 9/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1914 - accuracy: 0.9110\n",
            "Epoch 10/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1717 - accuracy: 0.9226\n",
            "Epoch 11/15\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.1553 - accuracy: 0.9327\n",
            "Epoch 12/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1502 - accuracy: 0.9327\n",
            "Epoch 13/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1291 - accuracy: 0.9423\n",
            "Epoch 14/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1431 - accuracy: 0.9389\n",
            "Epoch 15/15\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.1143 - accuracy: 0.9582\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.6964 - accuracy: 0.6149\n",
            "sec (579,)\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8018\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 10: Accuracy :0.8018 macro f1 :0.5459\n",
            "19/19 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n",
            "65/65 [==============================] - 2s 4ms/step - loss: 0.4031 - accuracy: 0.8009\n",
            "Epoch 2/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3208 - accuracy: 0.8427\n",
            "Epoch 3/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2945 - accuracy: 0.8543\n",
            "Epoch 4/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2719 - accuracy: 0.8629\n",
            "Epoch 5/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2791 - accuracy: 0.8624\n",
            "Epoch 6/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2562 - accuracy: 0.8749\n",
            "Epoch 7/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2374 - accuracy: 0.8855\n",
            "Epoch 8/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2249 - accuracy: 0.8855\n",
            "Epoch 9/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2205 - accuracy: 0.8908\n",
            "Epoch 10/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2083 - accuracy: 0.9048\n",
            "Epoch 11/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1824 - accuracy: 0.9153\n",
            "Epoch 12/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1794 - accuracy: 0.9158\n",
            "Epoch 13/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1676 - accuracy: 0.9235\n",
            "Epoch 14/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1660 - accuracy: 0.9235\n",
            "Epoch 15/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1643 - accuracy: 0.9269\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.7644 - accuracy: 0.5788\n",
            "sec (529,)\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7797\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 11: Accuracy :0.7797 macro f1 :0.4381\n",
            "17/17 [==============================] - 0s 2ms/step\n",
            "Epoch 1/15\n",
            "65/65 [==============================] - 2s 4ms/step - loss: 0.3721 - accuracy: 0.8312\n",
            "Epoch 2/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2978 - accuracy: 0.8514\n",
            "Epoch 3/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2629 - accuracy: 0.8658\n",
            "Epoch 4/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2373 - accuracy: 0.8903\n",
            "Epoch 5/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2538 - accuracy: 0.8826\n",
            "Epoch 6/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2178 - accuracy: 0.8951\n",
            "Epoch 7/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2351 - accuracy: 0.8913\n",
            "Epoch 8/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1992 - accuracy: 0.9081\n",
            "Epoch 9/15\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.1952 - accuracy: 0.9125\n",
            "Epoch 10/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1869 - accuracy: 0.9177\n",
            "Epoch 11/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1586 - accuracy: 0.9307\n",
            "Epoch 12/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1514 - accuracy: 0.9317\n",
            "Epoch 13/15\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.1306 - accuracy: 0.9471\n",
            "Epoch 14/15\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.1330 - accuracy: 0.9428\n",
            "Epoch 15/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1194 - accuracy: 0.9481\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.9359 - accuracy: 0.5544\n",
            "sec (479,)\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6906 - accuracy: 0.7797\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 12: Accuracy :0.7797 macro f1 :0.4381\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "Epoch 1/15\n",
            "65/65 [==============================] - 2s 4ms/step - loss: 0.4099 - accuracy: 0.8124\n",
            "Epoch 2/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3105 - accuracy: 0.8475\n",
            "Epoch 3/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2890 - accuracy: 0.8567\n",
            "Epoch 4/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2603 - accuracy: 0.8716\n",
            "Epoch 5/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2607 - accuracy: 0.8735\n",
            "Epoch 6/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2418 - accuracy: 0.8874\n",
            "Epoch 7/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2359 - accuracy: 0.8899\n",
            "Epoch 8/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2220 - accuracy: 0.8937\n",
            "Epoch 9/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1997 - accuracy: 0.9067\n",
            "Epoch 10/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1986 - accuracy: 0.9105\n",
            "Epoch 11/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1771 - accuracy: 0.9245\n",
            "Epoch 12/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1619 - accuracy: 0.9264\n",
            "Epoch 13/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1716 - accuracy: 0.9202\n",
            "Epoch 14/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1611 - accuracy: 0.9327\n",
            "Epoch 15/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1340 - accuracy: 0.9442\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.7851 - accuracy: 0.5871\n",
            "sec (429,)\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.5375 - accuracy: 0.7797\n",
            "33/33 [==============================] - 0s 3ms/step\n",
            "after query 13: Accuracy :0.7797 macro f1 :0.4381\n",
            "14/14 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n",
            "65/65 [==============================] - 2s 4ms/step - loss: 0.3741 - accuracy: 0.8254\n",
            "Epoch 2/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2946 - accuracy: 0.8543\n",
            "Epoch 3/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2610 - accuracy: 0.8672\n",
            "Epoch 4/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2349 - accuracy: 0.8971\n",
            "Epoch 5/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2576 - accuracy: 0.8648\n",
            "Epoch 6/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2245 - accuracy: 0.8879\n",
            "Epoch 7/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2179 - accuracy: 0.9019\n",
            "Epoch 8/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1976 - accuracy: 0.9081\n",
            "Epoch 9/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1851 - accuracy: 0.9187\n",
            "Epoch 10/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1687 - accuracy: 0.9240\n",
            "Epoch 11/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1553 - accuracy: 0.9278\n",
            "Epoch 12/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1384 - accuracy: 0.9327\n",
            "Epoch 13/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1255 - accuracy: 0.9509\n",
            "Epoch 14/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1265 - accuracy: 0.9442\n",
            "Epoch 15/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1247 - accuracy: 0.9456\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.9768 - accuracy: 0.5731\n",
            "sec (379,)\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.7956\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 14: Accuracy :0.7956 macro f1 :0.5323\n",
            "12/12 [==============================] - 0s 2ms/step\n",
            "Epoch 1/15\n",
            "65/65 [==============================] - 2s 4ms/step - loss: 0.4072 - accuracy: 0.8158\n",
            "Epoch 2/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3068 - accuracy: 0.8576\n",
            "Epoch 3/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2747 - accuracy: 0.8644\n",
            "Epoch 4/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2407 - accuracy: 0.8874\n",
            "Epoch 5/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2605 - accuracy: 0.8769\n",
            "Epoch 6/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2239 - accuracy: 0.8937\n",
            "Epoch 7/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2063 - accuracy: 0.9076\n",
            "Epoch 8/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2003 - accuracy: 0.9086\n",
            "Epoch 9/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2057 - accuracy: 0.9096\n",
            "Epoch 10/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1787 - accuracy: 0.9197\n",
            "Epoch 11/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1410 - accuracy: 0.9380\n",
            "Epoch 12/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1395 - accuracy: 0.9432\n",
            "Epoch 13/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1320 - accuracy: 0.9413\n",
            "Epoch 14/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1276 - accuracy: 0.9500\n",
            "Epoch 15/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1073 - accuracy: 0.9553\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6899 - accuracy: 0.6861\n",
            "sec (329,)\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.5561 - accuracy: 0.7797\n",
            "33/33 [==============================] - 0s 3ms/step\n",
            "after query 15: Accuracy :0.7797 macro f1 :0.4381\n",
            "11/11 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n",
            "65/65 [==============================] - 2s 4ms/step - loss: 0.3969 - accuracy: 0.8081\n",
            "Epoch 2/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3240 - accuracy: 0.8446\n",
            "Epoch 3/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2934 - accuracy: 0.8610\n",
            "Epoch 4/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2745 - accuracy: 0.8648\n",
            "Epoch 5/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2782 - accuracy: 0.8605\n",
            "Epoch 6/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2580 - accuracy: 0.8701\n",
            "Epoch 7/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2453 - accuracy: 0.8783\n",
            "Epoch 8/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2319 - accuracy: 0.8817\n",
            "Epoch 9/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2358 - accuracy: 0.8860\n",
            "Epoch 10/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2068 - accuracy: 0.8995\n",
            "Epoch 11/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1838 - accuracy: 0.9134\n",
            "Epoch 12/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1860 - accuracy: 0.9168\n",
            "Epoch 13/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1697 - accuracy: 0.9202\n",
            "Epoch 14/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1551 - accuracy: 0.9293\n",
            "Epoch 15/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1613 - accuracy: 0.9293\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.7771 - accuracy: 0.5584\n",
            "sec (279,)\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5249 - accuracy: 0.7797\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 16: Accuracy :0.7797 macro f1 :0.4381\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "Epoch 1/15\n",
            "65/65 [==============================] - 2s 4ms/step - loss: 0.3810 - accuracy: 0.8225\n",
            "Epoch 2/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2950 - accuracy: 0.8519\n",
            "Epoch 3/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2689 - accuracy: 0.8653\n",
            "Epoch 4/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2406 - accuracy: 0.8865\n",
            "Epoch 5/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2687 - accuracy: 0.8634\n",
            "Epoch 6/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2316 - accuracy: 0.8836\n",
            "Epoch 7/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2346 - accuracy: 0.8860\n",
            "Epoch 8/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.2175 - accuracy: 0.9009\n",
            "Epoch 9/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1965 - accuracy: 0.9091\n",
            "Epoch 10/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1965 - accuracy: 0.9115\n",
            "Epoch 11/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1682 - accuracy: 0.9230\n",
            "Epoch 12/15\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.1572 - accuracy: 0.9288\n",
            "Epoch 13/15\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.1474 - accuracy: 0.9360\n",
            "Epoch 14/15\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.1531 - accuracy: 0.9312\n",
            "Epoch 15/15\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.1307 - accuracy: 0.9456\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6474 - accuracy: 0.7122\n",
            "sec (229,)\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7797\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 17: Accuracy :0.7797 macro f1 :0.4381\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "Epoch 1/15\n",
            "65/65 [==============================] - 2s 4ms/step - loss: 0.3946 - accuracy: 0.8201\n",
            "Epoch 2/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2984 - accuracy: 0.8533\n",
            "Epoch 3/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2726 - accuracy: 0.8624\n",
            "Epoch 4/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2425 - accuracy: 0.8846\n",
            "Epoch 5/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2729 - accuracy: 0.8721\n",
            "Epoch 6/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2300 - accuracy: 0.8850\n",
            "Epoch 7/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2304 - accuracy: 0.8889\n",
            "Epoch 8/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2109 - accuracy: 0.9014\n",
            "Epoch 9/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1889 - accuracy: 0.9096\n",
            "Epoch 10/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1915 - accuracy: 0.9163\n",
            "Epoch 11/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1638 - accuracy: 0.9254\n",
            "Epoch 12/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1472 - accuracy: 0.9360\n",
            "Epoch 13/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1366 - accuracy: 0.9452\n",
            "Epoch 14/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1517 - accuracy: 0.9370\n",
            "Epoch 15/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.1178 - accuracy: 0.9514\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6215 - accuracy: 0.7356\n",
            "sec (179,)\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.7797\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 18: Accuracy :0.7797 macro f1 :0.4381\n",
            "6/6 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n",
            "65/65 [==============================] - 2s 4ms/step - loss: 0.3848 - accuracy: 0.8215\n",
            "Epoch 2/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3107 - accuracy: 0.8480\n",
            "Epoch 3/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2934 - accuracy: 0.8562\n",
            "Epoch 4/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2803 - accuracy: 0.8595\n",
            "Epoch 5/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2827 - accuracy: 0.8648\n",
            "Epoch 6/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2667 - accuracy: 0.8716\n",
            "Epoch 7/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2656 - accuracy: 0.8692\n",
            "Epoch 8/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2454 - accuracy: 0.8870\n",
            "Epoch 9/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2416 - accuracy: 0.8884\n",
            "Epoch 10/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2729 - accuracy: 0.8706\n",
            "Epoch 11/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2333 - accuracy: 0.8947\n",
            "Epoch 12/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2228 - accuracy: 0.8951\n",
            "Epoch 13/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2092 - accuracy: 0.9009\n",
            "Epoch 14/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2104 - accuracy: 0.9067\n",
            "Epoch 15/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1886 - accuracy: 0.9139\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.6491 - accuracy: 0.7174\n",
            "sec (129,)\n",
            "65/65 [==============================] - 1s 3ms/step - loss: 0.4034 - accuracy: 0.8066\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 19: Accuracy :0.8066 macro f1 :0.5965\n",
            "5/5 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n",
            "65/65 [==============================] - 2s 4ms/step - loss: 0.3723 - accuracy: 0.8316\n",
            "Epoch 2/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2997 - accuracy: 0.8547\n",
            "Epoch 3/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2687 - accuracy: 0.8706\n",
            "Epoch 4/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2428 - accuracy: 0.8860\n",
            "Epoch 5/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2522 - accuracy: 0.8778\n",
            "Epoch 6/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.2273 - accuracy: 0.8908\n",
            "Epoch 7/15\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.2231 - accuracy: 0.8894\n",
            "Epoch 8/15\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.2119 - accuracy: 0.9028\n",
            "Epoch 9/15\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.1946 - accuracy: 0.9076\n",
            "Epoch 10/15\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.1908 - accuracy: 0.9158\n",
            "Epoch 11/15\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.1685 - accuracy: 0.9230\n",
            "Epoch 12/15\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.1533 - accuracy: 0.9331\n",
            "Epoch 13/15\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.1408 - accuracy: 0.9404\n",
            "Epoch 14/15\n",
            "65/65 [==============================] - 0s 6ms/step - loss: 0.1336 - accuracy: 0.9452\n",
            "Epoch 15/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1266 - accuracy: 0.9437\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5469 - accuracy: 0.7742\n",
            "sec (79,)\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5943 - accuracy: 0.7797\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 20: Accuracy :0.7797 macro f1 :0.4427\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "Epoch 1/15\n",
            "65/65 [==============================] - 2s 4ms/step - loss: 0.3691 - accuracy: 0.8148\n",
            "Epoch 2/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3045 - accuracy: 0.8504\n",
            "Epoch 3/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2675 - accuracy: 0.8663\n",
            "Epoch 4/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2408 - accuracy: 0.8865\n",
            "Epoch 5/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2636 - accuracy: 0.8749\n",
            "Epoch 6/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2293 - accuracy: 0.8850\n",
            "Epoch 7/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2321 - accuracy: 0.8855\n",
            "Epoch 8/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2038 - accuracy: 0.9038\n",
            "Epoch 9/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1939 - accuracy: 0.9115\n",
            "Epoch 10/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1778 - accuracy: 0.9202\n",
            "Epoch 11/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1580 - accuracy: 0.9278\n",
            "Epoch 12/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1525 - accuracy: 0.9322\n",
            "Epoch 13/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1440 - accuracy: 0.9413\n",
            "Epoch 14/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1345 - accuracy: 0.9437\n",
            "Epoch 15/15\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1214 - accuracy: 0.9447\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.7706\n",
            "sec (29,)\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3685 - accuracy: 0.8398\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "after query 21: Accuracy :0.8398 macro f1 :0.7736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_25perc_avg=pref_hist_multy_f1[:,:int(0.25*N_QUERIES)].mean(0)\n",
        "\n",
        "print(f1_25perc_avg[-1])"
      ],
      "metadata": {
        "id": "hHqlXYjGyY2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_instance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pgHbVudogKC",
        "outputId": "681b87ce-0605-4e90-9c5d-543025dfcf51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.10937989, -0.32409355, -0.22804809, ..., -0.31877008,\n",
              "         0.3237741 ,  0.44401392],\n",
              "       [-0.12156366, -0.32348505, -0.238762  , ..., -0.3617471 ,\n",
              "         0.4970476 ,  0.5812354 ],\n",
              "       [-0.15743075, -0.46739998,  0.21498464, ..., -0.6134482 ,\n",
              "         0.10459223,  0.27613413],\n",
              "       ...,\n",
              "       [-0.15280154, -0.35130453,  0.1686634 , ..., -0.11777963,\n",
              "         0.29943648,  0.23850745],\n",
              "       [-0.15289503, -0.26090252,  0.11517086, ..., -0.12757997,\n",
              "         0.43884858,  0.32419595],\n",
              "       [-0.32888773, -0.08943853, -0.22164007, ..., -0.23371893,\n",
              "         0.47447217,  0.4885551 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 297
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBgywJGDm3jk",
        "outputId": "f362f4a2-4776-4d90-f3b2-e173070d476a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([222, 252, 158,   3, 105, 636, 930, 798, 488, 413, 559, 944,  38,\n",
              "       288, 822, 191, 857, 520, 302, 128, 946, 842, 121, 704, 820, 926,\n",
              "       956, 785, 836, 603, 176, 827, 273,  15, 517, 682, 750, 890, 840,\n",
              "       328, 925, 582, 834, 792, 228, 131, 708, 684, 193, 241])"
            ]
          },
          "metadata": {},
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_pool.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5nQy4JAlhz2",
        "outputId": "89a6f4bc-4fa4-4a48-d61a-97e8fd97a8a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1029, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 335
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRGFrUM3jwtO",
        "outputId": "e6d38c7a-3668-49e5-a288-3f6927c80c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltiFLxBdjztn",
        "outputId": "32116cc5-8018-4766-902e-c332d39751ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50,)"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8m7Z-wfdnMj",
        "outputId": "92be6b17-6896-46b2-b68a-8fd3a9e73b9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2079,)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mu4qNk8icNoA",
        "outputId": "958cfdcb-44b3-4f01-9e8d-479caae8dcab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsEgUPXOcpqE",
        "outputId": "f1120375-9a4f-4e87-f9db-3fa263351982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50,)"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_categorical.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsLU0r6BcsuP",
        "outputId": "8b9efa29-af20-484b-925a-18c1f34ce1b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0bOkzehcxWN",
        "outputId": "fa589d6e-f2d8-4c5b-b2a2-25162bde7427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20,)"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSSKkuwzSJI4"
      },
      "source": [
        "batch_size=128\n",
        "prediction_data=TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler=SequentialSampler(prediction_data)\n",
        "prediction_dataloader=DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
        "\n",
        "\n",
        "bert_tweet.cuda()\n",
        "bert_tweet.eval()\n",
        "\n",
        "# Tracking variables\n",
        "sentence_feature=[]\n",
        "t1=time.time()\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "  t0=time.time()\n",
        "\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  with torch.no_grad():\n",
        "      outputs=bert_tweet(b_input_ids, attention_mask=b_input_mask)\n",
        "\n",
        "  sentence_features_slice = outputs[0][:,0,:].cpu().numpy()\n",
        "\n",
        "  # Store predictions and true labels\n",
        "  sentence_feature.append(sentence_features_slice)\n",
        "  elapsed = format_time(time.time() - t0)\n",
        "\n",
        "  print(\"time elapse:\",elapsed)\n",
        "\n",
        "print(\"full time\",format_time(time.time()-t1))\n",
        "\n",
        "sentence_feature=np.concatenate(sentence_feature, axis=0)\n",
        "print(sentence_feature.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZCCzuZFGqow"
      },
      "source": [
        "with open('tweet_bert.npy', 'wb') as f:\n",
        "    np.save(f, sentence_feature)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}