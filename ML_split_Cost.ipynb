{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paridhika/DDL/blob/main/ML_split_Cost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# According to PyTorch"
      ],
      "metadata": {
        "id": "uN3qotb__Mq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet50\n",
        "import torch\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "ETJGbo7g_IqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(resnet50(), (3, 224, 224))"
      ],
      "metadata": {
        "id": "E0MxyiMD_WVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# According to TF"
      ],
      "metadata": {
        "id": "HZGYh8Sd_cG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "_DfmwWFc_v6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.applications.resnet.ResNet50(weights=None)\n",
        "model.summary();"
      ],
      "metadata": {
        "id": "FIvEneg__xM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get layers with tensors"
      ],
      "metadata": {
        "id": "Es2EGNx0Y4Ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.math_ops import sub\n",
        "# import tensorflow as tf\n",
        "# model = tf.keras.applications.resnet.ResNet50(weights='imagenet');\n",
        "# model.summary();\n",
        "import csv  \n",
        "layer_count = 0\n",
        "my_map = {}\n",
        "for i, layer in enumerate(model.layers):\n",
        "    if \"add\" not in layer.name:\n",
        "        layer_count += 1\n",
        "        # print(\"Layer {}: {} ({} parameters)\".format(layer_count, layer.name, layer.count_params()))\n",
        "        my_map[layer.name] = layer.count_params()\n",
        "  \n",
        "print(len(my_map))\n",
        "\n",
        "map_list = list(my_map.items())\n",
        "map_list.reverse()\n",
        "with open(\"tensor_layers.csv\", \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(map_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH8P5T57Y_Eb",
        "outputId": "c91ec407-7abe-46a3-964a-f24eb96921ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get layers with parameters"
      ],
      "metadata": {
        "id": "RO7kxoucZxRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.math_ops import sub\n",
        "# import tensorflow as tf\n",
        "# model = tf.keras.applications.resnet.ResNet50(weights='imagenet');\n",
        "# model.summary();\n",
        "import csv  \n",
        "layer_count = 0\n",
        "my_map = {}\n",
        "for i, layer in enumerate(model.layers):\n",
        "    if len(layer.weights) > 0:\n",
        "      if \"add\" not in layer.name:\n",
        "        layer_count += 1\n",
        "        # print(\"Layer {}: {} ({} parameters)\".format(layer_count, layer.name, layer.count_params()))\n",
        "        my_map[layer.name] = layer.count_params()\n",
        "  \n",
        "print(len(my_map))\n",
        "\n",
        "map_list = list(my_map.items())\n",
        "map_list.reverse()\n",
        "with open(\"parameters_layers.csv\", \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(map_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaKp_Oo3Z0oi",
        "outputId": "bbe350b7-6d58-4549-810a-105b9f8bc16a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute burst size"
      ],
      "metadata": {
        "id": "0OokMaVYPjXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.math_ops import sub\n",
        "# import tensorflow as tf\n",
        "# model = tf.keras.applications.resnet.ResNet50(weights='imagenet');\n",
        "# model.summary();\n",
        "import csv  \n",
        "layer_count = 0\n",
        "substring = \"\"\n",
        "my_map = {}\n",
        "\n",
        "\n",
        "for i, layer in enumerate(model.layers):\n",
        "    if len(layer.weights) > 0:\n",
        "      if \"_\" in layer.name:\n",
        "        layer_count += 1\n",
        "        # print(\"Layer {}: {} ({} parameters)\".format(layer_count, layer.name, layer.count_params()))\n",
        "        substring = layer.name[:layer.name.rindex(\"_\")]\n",
        "        if substring in my_map:\n",
        "          my_map[substring] = my_map[substring] + layer.count_params()\n",
        "        else:\n",
        "          my_map[substring] = layer.count_params()\n",
        "      else:\n",
        "        my_map[layer.name] = layer.count_params()\n",
        "  \n",
        "print(len(my_map))\n",
        "my_map[\"Layer Name\"] = \"Theoritical\"\n",
        "map_list = list(my_map.items())\n",
        "map_list.reverse()\n",
        "with open(\"my_map.csv\", \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(map_list)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtXakP2APrc2",
        "outputId": "ae9803a6-8164-4c91-e466-a98a6ed08ec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get table of comparison between theoritical and experimental burst sizes**"
      ],
      "metadata": {
        "id": "jjI6pNG5g_Ut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "def generate_latex_table(filename):\n",
        "    with open(filename, newline='') as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "        header = next(reader)\n",
        "        table = []\n",
        "        for row in reader:\n",
        "            table.append(row)\n",
        "        \n",
        "    table_string = \"\\\\begin{tabular}{|\" + \"c|\"*len(header) + \"}\\n\\\\hline\\n\"\n",
        "    table_string += \" & \".join(header) + \"\\\\\\\\\\n\\\\hline\\n\"\n",
        "    for row in table:\n",
        "        table_string += \" & \".join(row) + \"\\\\\\\\\\n\\\\hline\\n\"\n",
        "    table_string += \"\\\\end{tabular}\"\n",
        "    \n",
        "    return table_string\n",
        "\n",
        "numbers = [2049839.5,1048383.5,2359135.5,1048447.5,1048367.5,2359167.5,1048367.5,1048367.5,2096959.5,2359311.5,524079.5,262015.5,589647.5,261983.5,261951.5,589695.5,261951.5,262015.5,589615.5,261935.5,261935.5,589663.5,262015.5,262527.5,589615.5,261919.5,261935.5,524143.5,589599.5,130943.5,65359.5,147231.5,65375.5,65551.5,147247.5,65343.5,65391.5,147231.5,65327.5,65551.5,130879.5,147231.5,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "rounded_values = [int(round(number)) for number in numbers]\n",
        "\n",
        "# Load the existing CSV file into a pandas dataframe\n",
        "df = pd.read_csv(\"my_map.csv\")\n",
        "\n",
        "# Create a new column in the dataframe with the rounded integer values\n",
        "df[\"Experimental\"] = rounded_values\n",
        "\n",
        "# Save the updated dataframe to the existing CSV file\n",
        "df.to_csv(\"my_map.csv\", index=False)\n",
        "\n",
        "filename = 'my_map.csv'\n",
        "index_col = [i for i in range(1, 55)] #index column\n",
        "index_col = index_col[::-1]\n",
        "with open(filename, 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    header = next(reader) #get header\n",
        "    header.insert(0, 'Burst Count') #insert \"Index\" header in the first position\n",
        "    data = [row for row in reader] #get data\n",
        "\n",
        "#create new data with index column\n",
        "new_data = []\n",
        "for i, row in enumerate(data):\n",
        "    row.insert(0, index_col[i])\n",
        "    new_data.append(row)\n",
        "\n",
        "#write data to a new file\n",
        "with open('new_file.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(header)\n",
        "    writer.writerows(new_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "FTUIVtaDeERw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Open the CSV file for reading\n",
        "with open('new_file.csv', 'r') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    data = [row for row in reader]\n",
        "\n",
        "# Round off all floating point values to integers\n",
        "for i, row in enumerate(data):\n",
        "    data[i] = [int(float(cell)) if '.' in cell else cell for cell in row]\n",
        "\n",
        "# Write the updated data back to the same CSV file\n",
        "with open('final.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(data)\n",
        "\n"
      ],
      "metadata": {
        "id": "wQg4s5i5x9jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_string = generate_latex_table(\"new_file.csv\")\n",
        "with open('latex_bursts.tex', 'w') as f:\n",
        "        f.write(table_string)"
      ],
      "metadata": {
        "id": "yjUwWObHz0p3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compute number of parameters by formula**"
      ],
      "metadata": {
        "id": "nIX0x58yJ0Od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Instantiate the ResNet50 model\n",
        "model =  tf.keras.applications.resnet.ResNet50(weights=None) \n",
        "\n",
        "# Define a dictionary to store the number of operations for each layer\n",
        "ops_dict = {}\n",
        "param_dict = {}\n",
        "# Define a function to compute the number of operations for a Conv2D layer\n",
        "def compute_ops_conv2d(layer):\n",
        "    kernel_size = layer.kernel_size[0]\n",
        "    in_channels = layer.input_shape[-1]\n",
        "    out_channels = layer.output_shape[-1]\n",
        "    ops = kernel_size**2 * in_channels * out_channels\n",
        "    return ops\n",
        "\n",
        "# Define a function to compute the number of operations for a MaxPooling2D layer\n",
        "def compute_ops_maxpool2d(layer):\n",
        "    pool_size = layer.pool_size[0]\n",
        "    in_channels = layer.input_shape[-1]\n",
        "    ops = pool_size**2 * in_channels\n",
        "    return ops\n",
        "\n",
        "# Define a function to compute the number of operations for a ReLU layer\n",
        "def compute_ops_relu(layer):\n",
        "    num_elements = tf.reduce_prod(layer.input_shape[1:])\n",
        "    ops = num_elements\n",
        "    return ops\n",
        "\n",
        "# Define a function to compute the number of operations for the output layer\n",
        "def compute_ops_output(layer):\n",
        "    num_input_channels = layer.input_shape[-1]\n",
        "    num_output_channels = layer.output_shape[-1]\n",
        "    fc_ops = (num_input_channels * num_output_channels) + num_output_channels\n",
        "    if type(layer.activation) == tf.keras.activations.softmax or type(layer.activation) ==  tf.keras.activations.sigmoid:\n",
        "        num_elements = tf.reduce_prod(layer.output_shape[1:])\n",
        "        act_ops = num_elements\n",
        "    else:\n",
        "        act_ops = 0\n",
        "    ops = fc_ops + act_ops\n",
        "    return ops\n",
        "\n",
        "# Compute the number of operations for each layer in the model\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "        ops = compute_ops_conv2d(layer)\n",
        "    elif isinstance(layer, tf.keras.layers.MaxPooling2D):\n",
        "        ops = compute_ops_maxpool2d(layer)\n",
        "    elif isinstance(layer, tf.keras.layers.Activation) and type(layer.activation) == tf.keras.activations.relu:\n",
        "        ops = compute_ops_relu(layer)\n",
        "    elif isinstance(layer, tf.keras.layers.Dense):\n",
        "        ops = compute_ops_output(layer)\n",
        "    elif isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "        num_channels = layer.output_shape[-1]\n",
        "        ops = 4 * num_channels\n",
        "    else:\n",
        "        ops = 0\n",
        "    ops_dict[layer.name] = ops\n",
        "    param_dict[layer.name] = layer.count_params()\n",
        "# Print the number of operations for each layer in the model\n",
        "for layer_name, ops in ops_dict.items():\n",
        "    print(layer_name, ops, param_dict[layer_name])\n"
      ],
      "metadata": {
        "id": "Q5IPj3YOEwAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make plot for comparison**"
      ],
      "metadata": {
        "id": "a3Y8rY0a45k8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the csv file into a pandas DataFrame\n",
        "df = pd.read_csv('my_map.csv')\n",
        "\n",
        "# Extract the two columns you need\n",
        "col1 = df['Theoritical']\n",
        "col2 = df['Experimental']\n",
        "\n",
        "# Plot the histogram\n",
        "plt.plot(df.iloc[:43, 1]/1000000, color='blue', label='Theoritical')\n",
        "plt.plot(df.iloc[:43, 2]/1000000, color='red', label='Experimental')\n",
        "\n",
        "# Add a legend and labels for the x and y axes\n",
        "plt.legend()\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('Data (MB)')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aaoQ80nJ4-Y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute computation time"
      ],
      "metadata": {
        "id": "wNLSamFKnlos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Instantiate the ResNet50 model\n",
        "model =  tf.keras.applications.resnet.ResNet50(weights=None) \n",
        "\n",
        "# Print the input and output shape for each convolutional layer in the model\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "      print(layer.name, layer.input_shape, layer.output_shape,  layer.kernel_size, layer.filters)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JeLauYSmnr0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.api._v2.keras.layers import Activation\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "# from tf.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "\n",
        "\n",
        "# Instantiate the ResNet50 model\n",
        "# model =  tf.keras.applications.resnet.ResNet50(weights=None) \n",
        "# model = tf.keras.applications.vgg16.VGG16(weights=None) \n",
        "# model =  tf.keras.applications.resnet.ResNet152(weights='imagenet') \n",
        "# model =  tf.keras.applications.InceptionResNetV2(weights=None) \n",
        "# model.summary()\n",
        "\n",
        "# Define the input shape of the model\n",
        "input_shape = model.input_shape[1:]\n",
        "\n",
        "# Generate a random image with the input shape of the model\n",
        "random_image = np.random.rand(*input_shape)\n",
        "\n",
        "# Preprocess the image\n",
        "preprocessed_image = tf.keras.applications.resnet50.preprocess_input(random_image)\n",
        "\n",
        "# Make a prediction with the model\n",
        "prediction = model.predict(np.array([preprocessed_image]))\n",
        "\n",
        "# Decode the prediction\n",
        "decoded_prediction = tf.keras.applications.resnet50.decode_predictions(prediction, top=1)[0][0]\n",
        "\n",
        "# Print the decoded prediction\n",
        "print(decoded_prediction)\n",
        "\n",
        "# Define a dictionary to store the number of operations for each layer\n",
        "ops_dict = {}\n",
        "\n",
        "batch_size = 32\n",
        "model_input_shape = (batch_size, 224, 224, 3)\n",
        "\n",
        "# Define a function to compute the number of operations for a Conv2D layer\n",
        "def compute_ops_conv2d(layer):\n",
        "    kernel_size = layer.kernel_size[0]\n",
        "    in_channels = layer.input_shape[-1]\n",
        "    out_channels = layer.output_shape[-1]\n",
        "    input_height, input_width = layer.input_shape[1:3]\n",
        "    output_height, output_width = layer.output_shape[1:3]\n",
        "    ops = kernel_size**2 * in_channels * output_height * output_width * out_channels\n",
        "    return ops * batch_size\n",
        "\n",
        "# Define a function to compute the number of operations for a MaxPooling2D layer\n",
        "def compute_ops_maxpool2d(layer):\n",
        "    pool_size = layer.pool_size[0]\n",
        "    in_channels = layer.input_shape[-1]\n",
        "    input_height, input_width = layer.input_shape[1:3]\n",
        "    output_height, output_width = layer.output_shape[1:3]\n",
        "    ops = pool_size**2 * in_channels * output_height * output_width\n",
        "    return ops * batch_size\n",
        "\n",
        "# Define a function to compute the number of operations for a BatchNormalization layer\n",
        "def compute_ops_batchnorm(layer):\n",
        "    # Get input shape\n",
        "    input_shape = layer.input_shape[1:]\n",
        "    in_channels = input_shape[-1]\n",
        "\n",
        "    # Number of operations per element (2 for mean and variance)\n",
        "    ops = 2 * in_channels\n",
        "\n",
        "    return ops * batch_size\n",
        "\n",
        "# Define a function to compute the number of operations for a ReLU layer\n",
        "def compute_ops_relu(layer):\n",
        "\n",
        "    input_shape = layer.input_shape[1:]\n",
        "    # Number of operations per element\n",
        "    ops = 1\n",
        "    for dim in input_shape:\n",
        "        ops *= dim\n",
        "\n",
        "    return ops * batch_size\n",
        "\n",
        "# Define a function to compute the number of operations for the output layer\n",
        "def compute_ops_output(layer):\n",
        "    num_input_channels = layer.input_shape[-1]\n",
        "    num_output_channels = layer.output_shape[-1]\n",
        "    fc_ops = (num_input_channels * num_output_channels) + num_output_channels\n",
        "    if type(layer.activation) == tf.keras.activations.softmax or type(layer.activation) == tf.keras.activations.sigmoid:\n",
        "        num_elements = tf.reduce_prod(layer.output_shape[1:])\n",
        "        act_ops = num_elements\n",
        "    else:\n",
        "        act_ops = 0\n",
        "    ops = fc_ops + act_ops\n",
        "    return ops * batch_size\n",
        "\n",
        "# Print the number of operations for each layer in the model\n",
        "sum = 0;\n",
        "\n",
        "\n",
        "# Compute the number of operations for each layer in the model\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "        ops = compute_ops_conv2d(layer)\n",
        "    elif isinstance(layer, tf.keras.layers.MaxPooling2D):\n",
        "        ops = compute_ops_maxpool2d(layer)\n",
        "    elif isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "        ops = compute_ops_batchnorm(layer)\n",
        "    elif isinstance(layer, tf.keras.layers.Activation):\n",
        "        ops = compute_ops_relu(layer)\n",
        "    elif isinstance(layer, tf.keras.layers.Dense):\n",
        "        ops = compute_ops_output(layer)\n",
        "    else:\n",
        "        ops = 0\n",
        "    ops_dict[layer.name] = [ops,layer.input_shape, layer.output_shape]\n",
        "    # print(layer.name, ops, layer.input_shape)\n",
        "\n",
        "i = 0\n",
        "for layer_name, (ops, inp, out) in ops_dict.items():\n",
        "    sum = sum + ops\n",
        "    inp_size = 0\n",
        "\n",
        "    \n",
        "\n",
        "    if inp[0] is not None:\n",
        "      (n,l,h,w) = inp[0]\n",
        "      inp_size += l*h*w*batch_size/1000000\n",
        "      \n",
        "      if len(inp) == 2:\n",
        "        (n,l,h,w) = inp[1]\n",
        "        inp_size += l*h*w*batch_size/1000000\n",
        "\n",
        "    elif len(inp) > 2:\n",
        "      inp_size += inp[1]*inp[2] * inp[3] * batch_size/1000000\n",
        "    else:\n",
        "      inp_size += inp[1] * batch_size/1000000\n",
        "\n",
        "    if i == 0:\n",
        "      (n,l,h,w) = inp[0]\n",
        "      i = i+10\n",
        "      params = l*h*w\n",
        "    print(layer_name, ops, inp_size)\n",
        "\n",
        "sum = sum/1000000000 #GFLOP\n",
        "GFLOP = sum\n",
        "print(f'input image : {params}')\n",
        "params = params * batch_size / 1000000\n",
        "print(f'GFLOP : {GFLOP}')\n",
        "\n",
        "print(f'Total input images : {params} MB')\n",
        "\n",
        "# print(f'Parameters Memory : 102 MB')"
      ],
      "metadata": {
        "id": "1b1o-QJFKJZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Edge : Model\t i9-11900K;\n",
        "#         Cores/Threads\t8/16\n",
        "#         Base Clock\t3.5 GHz\n",
        "#         Boost Clock\t5.3 GHz\n",
        "#         Cache\t  16 MB\n",
        "#         TDP\t  125W\n",
        "#         GFLOPs  925.6\n",
        "\n",
        "# Raspberry Pi 4 \n",
        "# GFLOPs 24 \n",
        "# Memory 1 to 8 GB\n",
        "\n",
        "\n",
        "Edge = 24\n",
        "CE = 0\n",
        "\n",
        "# Near the Edge : Model Intel Xeon E5-2666 v3\t\n",
        "# c4.16xlarge\tvCPUs 64\tGFLOPs 2144.0 \t$1.75/\n",
        "# c4.8xlarge\tvCPUs 36\tMemory 60 GiB\tEBS only\tOn Demand $1.59/hr\tReserved $1.01/hr\t\n",
        "# c4.large\tvCPUs 2\tMemory 3.75 GiB\tEBS only\tOn Demand $0.10/hr\tReserved $0.06/hr\tGFLOPs 67.2\n",
        "\n",
        "# c7g\n",
        "\n",
        "NTE = 1280\n",
        "CNTE = 1.53/3600 # cost per second\n",
        "\n",
        "# Cloud : inf1.24xlarge\t8x AWS Inferentia chips with 16 Neuron Cores each\t\n",
        "#  Memory 192 (GiB)\tTFLOPs\t42.0\n",
        "# inf1.24xlarge\tvCPUs 96\tNetwork b/w\t100\tEBS b/w 19\t$4.721/Hr\n",
        "# inf1.xlarge\tvCPUs 4\tMemory 8 GiB\tEBS only\tOn Demand $0.23/hr\tReserved $0.14/hr GFLOPs = 2250\n",
        "# inf2.48xlarge\tvCPUs 192\tMemory 768 GiB\tEBS only\tOn Demand $12.98/hr\tReserved $8.18/hr GFLOPs = 8,400,000\n",
        "\n",
        "# T4 GPU 65 TFLOPs\n",
        "Cloud = 65000\n",
        "# CC = 0.14/3600  # cost per second\n",
        "CC = 3.13/3600  # cost per second\n",
        "\n",
        "\n",
        "# cost model from Bell Network charges $0.3078 for transferring 1GB over its OC3 link -> 150 Mbps\n",
        "TCost = 307.8 # per MB\n",
        "print(f'Cost for transmission : ${params/TCost}')"
      ],
      "metadata": {
        "id": "2LDMdbGpkYlt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef7f6122-9db9-4ba4-dd56-ba006080147d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost for transmission : $0.0312988693957115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bandwidth = 1 Gbps \n",
        "# Transmission time from E to NTE\n",
        "BWENTE = 20\n",
        "TENTE = params/BWENTE\n",
        "\n",
        "PENTE = 0.001 # 1 ms\n",
        "PNTEC = 0.1 # 100 ms\n",
        "print(f'Transmission Time from Edge to Near the Edge : {TENTE} sec')\n",
        "\n",
        "print(f'Propagation Delay from Edge to Near the Edge : {PENTE} sec')\n",
        "\n",
        "\n",
        "\n",
        "# Bandwidth = 20 Mbps\n",
        "# Transmission time from E to Cloud\n",
        "BWNTEC = 200\n",
        "TNTEC = params/BWNTEC\n",
        "\n",
        "print(f'Transmission Time from Near the Edge to Cloud : {TNTEC} sec')\n",
        "print(f'Propagation Delay from Near the Edge to Cloud: {PNTEC} sec')\n",
        "\n",
        "TEC = TENTE + TNTEC\n",
        "PEC = PENTE + PNTEC\n",
        "print(f'Transmission Time from Edge to Cloud : {TEC} sec')\n",
        "print(f'Propagation Delay from Edge to Cloud: {PEC} sec')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLLJGDcjyOL1",
        "outputId": "26786802-ffdf-4feb-a46d-42002c1d672a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transmission Time from Edge to Near the Edge : 0.4816896 sec\n",
            "Propagation Delay from Edge to Near the Edge : 0.001 sec\n",
            "Transmission Time from Near the Edge to Cloud : 0.04816896 sec\n",
            "Propagation Delay from Near the Edge to Cloud: 0.1 sec\n",
            "Transmission Time from Edge to Cloud : 0.52985856 sec\n",
            "Propagation Delay from Edge to Cloud: 0.101 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TE = GFLOP / Edge\n",
        "TNTE = GFLOP / NTE\n",
        "TC = GFLOP / Cloud\n",
        "\n",
        "print(f'Time for excecution at Edge : {TE} secs')\n",
        "print(f'Time for excecution at NTE : {TNTE} secs')\n",
        "print(f'Time for excecution at Cloud : {TC} secs')\n",
        "\n",
        "print()\n",
        "\n",
        "print(f'Transmission Time from Edge to Near the Edge : {TENTE} sec')\n",
        "print(f'Transmission Time from Edge to Cloud : {TEC} sec')\n",
        "print()\n",
        "\n",
        "print(f'Total time at Near the Edge : {TNTE + TENTE + PENTE} sec')\n",
        "print(f'Total time at Cloud : {TEC + TC + PEC} sec')\n",
        "\n",
        "MCE = TE * CE\n",
        "MCNTE = TNTE * CNTE \n",
        "MCC = TC * CC\n",
        "print()\n",
        "print(f'Cost for excecution at Edge : ${MCE}')\n",
        "print(f'Cost for excecution at NTE : ${MCNTE}')\n",
        "print(f'Cost for excecution at Cloud : ${MCC}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tKWFEVbbgNM",
        "outputId": "b1d702e6-a3fb-4789-8860-98d65958c70a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for excecution at Edge : 30.146390293333337 secs\n",
            "Time for excecution at NTE : 0.565244818 secs\n",
            "Time for excecution at Cloud : 0.011130974877538462 secs\n",
            "\n",
            "Transmission Time from Edge to Near the Edge : 0.4816896 sec\n",
            "Transmission Time from Edge to Cloud : 0.52985856 sec\n",
            "\n",
            "Total time at Near the Edge : 1.0479344179999999 sec\n",
            "Total time at Cloud : 0.6419895348775384 sec\n",
            "\n",
            "Cost for excecution at Edge : $0.0\n",
            "Cost for excecution at NTE : $0.00024022904765000003\n",
            "Cost for excecution at Cloud : $9.677764268526496e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Memory required by ResNet152 = 242 MB (parameter) + 200 KB ( for intermediate activations)\n",
        "Mem = 242 # MB"
      ],
      "metadata": {
        "id": "Mw34lmFxQenG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT2 Model"
      ],
      "metadata": {
        "id": "iQ4Bk6LlJr87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers\n",
        "\n",
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2Model.from_pretrained('gpt2')\n",
        "text = \"Replace me by any text you'd like.\"\n",
        "encoded_input = tokenizer(text, return_tensors='pt')\n",
        "output = model(**encoded_input)\n"
      ],
      "metadata": {
        "id": "wRCmVwOr3NUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if 'weight' in name:\n",
        "        print(f'Layer: {name}, Shape: {param.shape}')"
      ],
      "metadata": {
        "id": "qmA5IWx84Lkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import GPT2Model\n",
        "\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "\n",
        "# Define the GPT-2 model\n",
        "model = GPT2Model.from_pretrained('gpt2')\n",
        "\n",
        "# Define the input\n",
        "input_ids = torch.randint(0, 1000, (1, 128))\n",
        "\n",
        "# Define the profiler\n",
        "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
        "    # Run the model\n",
        "    with record_function(\"model_inference\"):\n",
        "        with torch.no_grad():\n",
        "            output = model(input_ids)\n",
        "\n",
        "# Print the profiler results\n",
        "print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"self_cpu_time_total\", row_limit=10))\n"
      ],
      "metadata": {
        "id": "rQLVffYW7Tts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchprofile import profile_macs\n",
        "\n",
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "\n",
        "# Load the model\n",
        "# model = GPT2Model.from_pretrained('gpt2')\n",
        "\n",
        "# Create a sample input\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "input_str = 'Hello, how are you today?'\n",
        "input_ids = torch.tensor([tokenizer.encode(input_str)])\n",
        "\n",
        "# Compute the FLOPs of each layer in the model\n",
        "macs_list = [profile_macs(layer, (input_ids,)) for layer in model.modules()]\n",
        "for i, macs in enumerate(macs_list):\n",
        "    if macs is not None:\n",
        "        print(f\"Layer {i + 1} FLOPs: {macs}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "RFo0_i7372hK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2Model\n",
        "from torchprofile import profile_macs\n",
        "\n",
        "# define the model and input\n",
        "# model = GPT2Model.from_pretrained('gpt2')\n",
        "# input_ids = torch.randint(low=0, high=1000, size=(1, 512))\n",
        "\n",
        "# compute the FLOPs of each layer in the model\n",
        "macs_list = {}\n",
        "for module in model.modules():\n",
        "    if hasattr(module, 'forward') and module.forward.__code__.co_argcount > 1:\n",
        "        macs_list.append(profile_macs(module, (input_ids,)))\n",
        "\n",
        "\n",
        "for i, macs in enumerate(macs_list):\n",
        "    print(f\"Layer {i + 1} FLOPs: {macs}\")\n"
      ],
      "metadata": {
        "id": "0FEzd7w089eP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install thop\n",
        "import torch\n",
        "from transformers import GPT2Model\n",
        "from thop import profile\n",
        "\n",
        "# define the model and input\n",
        "model = GPT2Model.from_pretrained('gpt2')\n",
        "input_ids = torch.randint(low=0, high=1000, size=(1, 512))\n",
        "\n",
        "# compute the FLOPs of each layer in the model\n",
        "flops_list = []\n",
        "for name, module in model.named_modules():\n",
        "    if isinstance(module, torch.nn.Linear) or isinstance(module, torch.nn.MultiheadAttention):\n",
        "        input_size = (input_ids.size(0),) + tuple(module.in_proj_weight.shape[1:])\n",
        "        flops, params = profile(module, inputs=(input_ids,), verbose=False)\n",
        "        flops_list.append((name, flops))\n",
        "        \n",
        "for i, (name, flops) in enumerate(flops_list):\n",
        "    print(f\"Layer {i + 1} ({name}) FLOPs: {flops}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vBnefpVFIVTI"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard\n"
      ],
      "metadata": {
        "id": "6xRYO57qAzOY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import plot_model\n",
        "from datetime import datetime\n",
        "\n",
        "# Set up log directory for TensorBoard\n",
        "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "# Define a Keras callback for TensorBoard\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "# Plot the model graph and save as image file\n",
        "plot_model(model, to_file='resnet50.png')\n",
        "\n",
        "# Launch TensorBoard\n",
        "!tensorboard --logdir logs\n"
      ],
      "metadata": {
        "id": "490qctxTBcSt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc586451-193b-4ac5-97e7-7cfafcf93b65"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-05 17:00:41.145573: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.33' not found (required by /usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server)\n",
            "/usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.34' not found (required by /usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server)\n",
            "/usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.32' not found (required by /usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server)\n",
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.12.2 at http://localhost:6006/ (Press CTRL+C to quit)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding Model Summary"
      ],
      "metadata": {
        "id": "lMga9u2O_6BF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.applications.resnet.ResNet50(weights='imagenet');\n",
        "model.summary();\n",
        "len(model.layers)\n",
        "trainableLayerNameList = [layer.name for layer in model.layers if layer.trainable_variables]\n",
        "print(len(trainableLayerNameList));"
      ],
      "metadata": {
        "id": "_KhiPXEdPTXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainable = 0\n",
        "\n",
        "# iterate over the layers in the model\n",
        "for layer in model.layers:\n",
        "    # check if the layer has trainable parameters\n",
        "    if layer.trainable_variables:\n",
        "        # if the layer has trainable parameters, increment the counter\n",
        "        trainable += 1\n",
        "\n",
        "# print the number of layers involved in the AllReduce operation\n",
        "print(f'Number of layers with trainable parameters: {trainable}')"
      ],
      "metadata": {
        "id": "ybE7ry0qP1pz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ed9d609-c4cd-4b71-e318-840ef9ff71c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of layers with trainable parameters: 107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "allreduce_layers = 0;\n",
        "for layer in model.layers:\n",
        "    # check if the layer has trainable parameters\n",
        "    if not layer.trainable_variables:\n",
        "        # if the layer has trainable parameters, increment the counter\n",
        "        if \"add\" in layer.name:\n",
        "          allreduce_layers += 1\n",
        "          \n",
        "# print the number of layers involved in the AllReduce operation\n",
        "print(f'Number of layers not involved in AllReduce: {allreduce_layers}')\n",
        "print(f'Number of layers involved in AllReduce: {len(model.layers) - allreduce_layers}')"
      ],
      "metadata": {
        "id": "gCohVvkkRyF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "resnet101 = tf.keras.applications.resnet.ResNet101(weights='imagenet')\n",
        "len(resnet101.layers)\n",
        "trainableLayerNameList = [layer.name for layer in resnet101.layers if layer.trainable_variables]\n",
        "print(len(trainableLayerNameList));\n",
        "allreduce_layers = 0;\n",
        "for layer in resnet101.layers:\n",
        "    # check if the layer has trainable parameters\n",
        "    if not layer.trainable_variables:\n",
        "        if \"add\" in layer.name:\n",
        "          allreduce_layers += 1\n",
        "          # print(layer.name);\n",
        "print(f'Number of layers not involved in AllReduce: {allreduce_layers}')"
      ],
      "metadata": {
        "id": "YQ-t2GJ_gcZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16 = tf.keras.applications.vgg16.VGG16(weights=None)\n",
        "vgg16.summary();\n",
        "print(f'Number of layers : {len(vgg16.layers)}')\n",
        "trainableLayerNameList = [layer.name for layer in vgg16.layers if layer.trainable_variables]\n",
        "# print(len(trainableLayerNameList));\n",
        "allreduce_layers = 0;\n",
        "for layer in vgg16.layers:\n",
        "    # check if the layer has trainable parameters\n",
        "    if not layer.trainable_variables:\n",
        "        if \"add\" in layer.name:\n",
        "          allreduce_layers += 1\n",
        "          # print(layer.name);\n",
        "print(f'Number of layers not involved in AllReduce: {allreduce_layers}')"
      ],
      "metadata": {
        "id": "5Yla5IXykM7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "conv2d = 0;\n",
        "for layer in vgg16.layers:\n",
        "  if \"_conv\" in layer.name:\n",
        "    conv2d += 1;\n",
        "print(conv2d);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFoMUcturFkA",
        "outputId": "b2bf6d59-6d63-4122-bfa0-1d3d8a260f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainableLayerNameList)"
      ],
      "metadata": {
        "id": "zynCYzoFy_VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DNN Computational Graph Visualization"
      ],
      "metadata": {
        "id": "9QWBcOWJg5k-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchviz\n",
        "import torch\n",
        "import torchviz\n",
        "import torchvision.models as models\n",
        "\n",
        "# Load the ResNet50 model\n",
        "resnet = models.resnet50(pretrained=False)\n",
        "\n",
        "# Create a random input tensor\n",
        "x = torch.randn(1, 3, 224, 224)\n",
        "\n",
        "# Generate the output tensor and the computational graph\n",
        "y = resnet(x)\n",
        "dot = torchviz.make_dot(y, params=dict(resnet.named_parameters()))\n",
        "\n",
        "# Save the graph to a PDF file\n",
        "dot.render('resnet50_graph')\n",
        "\n",
        "# Display the graph in Jupyter notebook (optional)\n",
        "# dot\n"
      ],
      "metadata": {
        "id": "wQ6dU7tIZfRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchviz\n",
        "\n",
        "# Load the ResNet50 model\n",
        "resnet = torch.hub.load('pytorch/vision', 'resnet50', pretrained=False)\n",
        "\n",
        "# Create a random input tensor\n",
        "x = torch.randn(1, 3, 224, 224)\n",
        "\n",
        "# Generate the output tensor and the computational graph\n",
        "y = resnet(x)\n",
        "graph = torchviz.make_dot(y, params=dict(resnet.named_parameters()))\n",
        "\n",
        "# Get the input size for each layer\n",
        "input_sizes = {}\n",
        "for name, module in resnet.named_modules():\n",
        "    if isinstance(module, nn.Conv2d):\n",
        "        input_sizes[name] = x.shape[2:]\n",
        "    elif isinstance(module, nn.MaxPool2d):\n",
        "        x = module(x)\n",
        "        input_sizes[name] = x.shape[2:]\n",
        "\n",
        "# Print the input size for each layer\n",
        "for name, size in input_sizes.items():\n",
        "    print(f\"{name}: {size}\")\n",
        "\n",
        "# Save the graph in a PDF file\n",
        "graph.render(\"resnet50_graph\")\n"
      ],
      "metadata": {
        "id": "OZ10yoYzpFgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# Load the ResNet50 model\n",
        "resnet = nn.Sequential(*list(torch.hub.load('pytorch/vision', 'resnet50', pretrained=False).children())[:-1])\n",
        "\n",
        "# Create a random input tensor\n",
        "x = Variable(torch.randn(1, 3, 224, 224))\n",
        "\n",
        "# Get the computational graph\n",
        "nodes = list(resnet(x).graph.nodes())\n",
        "\n",
        "# Create a dictionary to store the results\n",
        "result_dict = {}\n",
        "\n",
        "# Loop over the nodes and calculate the input and output sizes\n",
        "for i, node in enumerate(nodes):\n",
        "    # Get the input and output shapes\n",
        "    input_shape = node.inputs()[0].type().sizes()\n",
        "    output_shape = node.outputs()[0].type().sizes()\n",
        "    \n",
        "    # Calculate the number of FLOPs for the node\n",
        "    if node.kind() == 'aten::conv2d':\n",
        "        kernel_size = node['kernel_size']\n",
        "        stride = node['stride']\n",
        "        padding = node['padding']\n",
        "        dilation = node['dilation']\n",
        "        in_channels = input_shape[1]\n",
        "        out_channels = output_shape[1]\n",
        "        output_height = output_shape[2]\n",
        "        output_width = output_shape[3]\n",
        "        kernel_height = kernel_size[0]\n",
        "        kernel_width = kernel_size[1]\n",
        "        num_flops = (2 * kernel_height * kernel_width * in_channels * out_channels * output_height * output_width) / stride[0] / stride[1] / dilation[0] / dilation[1]\n",
        "    elif node.kind() == 'aten::max_pool2d':\n",
        "        kernel_size = node['kernel_size']\n",
        "        stride = node['stride']\n",
        "        padding = node['padding']\n",
        "        dilation = node['dilation']\n",
        "        input_height = input_shape[2]\n",
        "        input_width = input_shape[3]\n",
        "        output_height = output_shape[2]\n",
        "        output_width = output_shape[3]\n",
        "        kernel_height = kernel_size[0]\n",
        "        kernel_width = kernel_size[1]\n",
        "        num_flops = kernel_height * kernel_width * input_shape[1] * output_height * output_width / stride[0] / stride[1] / dilation[0] / dilation[1]\n",
        "    else:\n",
        "        num_flops = 0\n",
        "        \n",
        "    # Calculate the input and output sizes in terms of bytes\n",
        "    input_size = torch.prod(torch.tensor(input_shape)).item() * 4 # Assume float32\n",
        "    output_size = torch.prod(torch.tensor(output_shape)).item() * 4 # Assume float32\n",
        "    \n",
        "    # Add the results to the dictionary\n",
        "    result_dict[f'Node {i}'] = {\n",
        "        'Input shape': input_shape,\n",
        "        'Output shape': output_shape,\n",
        "        'Input size (bytes)': input_size,\n",
        "        'Output size (bytes)': output_size,\n",
        "        'FLOPs': num_flops\n",
        "    }\n",
        "\n",
        "# Print the results\n",
        "print(result_dict)\n",
        "\n",
        "# Save the results to a file\n",
        "import csv\n",
        "\n",
        "with open('resnet50_results.csv', mode='w') as file:\n",
        "    writer = csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "    writer.writerow(['Node', 'Input shape', 'Output shape', 'Input size (bytes)', 'Output size (bytes)', 'FLOPs'])\n",
        "    for i in range(len(result_dict)):\n",
        "        row = [i, result_dict[f'Node {i}']['Input shape'], result_dict[f'Node {i}']['Output shape'], result_dict[f'Node {i}']['Input size (bytes)'], result_dict[f'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "jxFBFOyKg3Wn",
        "outputId": "1c27946f-8af8-44f5-d907-30c744dbe975"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-283daa342448>\"\u001b[0;36m, line \u001b[0;32m74\u001b[0m\n\u001b[0;31m    row = [i, result_dict[f'Node {i}']['Input shape'], result_dict[f'Node {i}']['Output shape'], result_dict[f'Node {i}']['Input size (bytes)'], result_dict[f'\u001b[0m\n\u001b[0m                                                                                                                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 74)\n"
          ]
        }
      ]
    }
  ]
}