{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paridhika/DDL/blob/main/ML_split_Cost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# According to PyTorch"
      ],
      "metadata": {
        "id": "uN3qotb__Mq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet50\n",
        "import torch\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "ETJGbo7g_IqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(resnet50(), (3, 224, 224))"
      ],
      "metadata": {
        "id": "E0MxyiMD_WVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# According to TF"
      ],
      "metadata": {
        "id": "HZGYh8Sd_cG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "_DfmwWFc_v6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.applications.resnet.ResNet50(weights=None)\n",
        "model.summary();"
      ],
      "metadata": {
        "id": "FIvEneg__xM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get layers with tensors"
      ],
      "metadata": {
        "id": "Es2EGNx0Y4Ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.math_ops import sub\n",
        "# import tensorflow as tf\n",
        "# model = tf.keras.applications.resnet.ResNet50(weights='imagenet');\n",
        "# model.summary();\n",
        "import csv  \n",
        "layer_count = 0\n",
        "my_map = {}\n",
        "for i, layer in enumerate(model.layers):\n",
        "    if \"add\" not in layer.name:\n",
        "        layer_count += 1\n",
        "        # print(\"Layer {}: {} ({} parameters)\".format(layer_count, layer.name, layer.count_params()))\n",
        "        my_map[layer.name] = layer.count_params()\n",
        "  \n",
        "print(len(my_map))\n",
        "\n",
        "map_list = list(my_map.items())\n",
        "map_list.reverse()\n",
        "with open(\"tensor_layers.csv\", \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(map_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH8P5T57Y_Eb",
        "outputId": "c91ec407-7abe-46a3-964a-f24eb96921ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get layers with parameters"
      ],
      "metadata": {
        "id": "RO7kxoucZxRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.math_ops import sub\n",
        "# import tensorflow as tf\n",
        "# model = tf.keras.applications.resnet.ResNet50(weights='imagenet');\n",
        "# model.summary();\n",
        "import csv  \n",
        "layer_count = 0\n",
        "my_map = {}\n",
        "for i, layer in enumerate(model.layers):\n",
        "    if len(layer.weights) > 0:\n",
        "      if \"add\" not in layer.name:\n",
        "        layer_count += 1\n",
        "        # print(\"Layer {}: {} ({} parameters)\".format(layer_count, layer.name, layer.count_params()))\n",
        "        my_map[layer.name] = layer.count_params()\n",
        "  \n",
        "print(len(my_map))\n",
        "\n",
        "map_list = list(my_map.items())\n",
        "map_list.reverse()\n",
        "with open(\"parameters_layers.csv\", \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(map_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaKp_Oo3Z0oi",
        "outputId": "bbe350b7-6d58-4549-810a-105b9f8bc16a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute burst size"
      ],
      "metadata": {
        "id": "0OokMaVYPjXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.math_ops import sub\n",
        "# import tensorflow as tf\n",
        "# model = tf.keras.applications.resnet.ResNet50(weights='imagenet');\n",
        "# model.summary();\n",
        "import csv  \n",
        "layer_count = 0\n",
        "substring = \"\"\n",
        "my_map = {}\n",
        "\n",
        "\n",
        "for i, layer in enumerate(model.layers):\n",
        "    if len(layer.weights) > 0:\n",
        "      if \"_\" in layer.name:\n",
        "        layer_count += 1\n",
        "        # print(\"Layer {}: {} ({} parameters)\".format(layer_count, layer.name, layer.count_params()))\n",
        "        substring = layer.name[:layer.name.rindex(\"_\")]\n",
        "        if substring in my_map:\n",
        "          my_map[substring] = my_map[substring] + layer.count_params()\n",
        "        else:\n",
        "          my_map[substring] = layer.count_params()\n",
        "      else:\n",
        "        my_map[layer.name] = layer.count_params()\n",
        "  \n",
        "print(len(my_map))\n",
        "my_map[\"Layer Name\"] = \"Theoritical\"\n",
        "map_list = list(my_map.items())\n",
        "map_list.reverse()\n",
        "with open(\"my_map.csv\", \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(map_list)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtXakP2APrc2",
        "outputId": "ae9803a6-8164-4c91-e466-a98a6ed08ec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get table of comparison between theoritical and experimental burst sizes**"
      ],
      "metadata": {
        "id": "jjI6pNG5g_Ut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "def generate_latex_table(filename):\n",
        "    with open(filename, newline='') as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "        header = next(reader)\n",
        "        table = []\n",
        "        for row in reader:\n",
        "            table.append(row)\n",
        "        \n",
        "    table_string = \"\\\\begin{tabular}{|\" + \"c|\"*len(header) + \"}\\n\\\\hline\\n\"\n",
        "    table_string += \" & \".join(header) + \"\\\\\\\\\\n\\\\hline\\n\"\n",
        "    for row in table:\n",
        "        table_string += \" & \".join(row) + \"\\\\\\\\\\n\\\\hline\\n\"\n",
        "    table_string += \"\\\\end{tabular}\"\n",
        "    \n",
        "    return table_string\n",
        "\n",
        "numbers = [2049839.5,1048383.5,2359135.5,1048447.5,1048367.5,2359167.5,1048367.5,1048367.5,2096959.5,2359311.5,524079.5,262015.5,589647.5,261983.5,261951.5,589695.5,261951.5,262015.5,589615.5,261935.5,261935.5,589663.5,262015.5,262527.5,589615.5,261919.5,261935.5,524143.5,589599.5,130943.5,65359.5,147231.5,65375.5,65551.5,147247.5,65343.5,65391.5,147231.5,65327.5,65551.5,130879.5,147231.5,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "rounded_values = [int(round(number)) for number in numbers]\n",
        "\n",
        "# Load the existing CSV file into a pandas dataframe\n",
        "df = pd.read_csv(\"my_map.csv\")\n",
        "\n",
        "# Create a new column in the dataframe with the rounded integer values\n",
        "df[\"Experimental\"] = rounded_values\n",
        "\n",
        "# Save the updated dataframe to the existing CSV file\n",
        "df.to_csv(\"my_map.csv\", index=False)\n",
        "\n",
        "filename = 'my_map.csv'\n",
        "index_col = [i for i in range(1, 55)] #index column\n",
        "index_col = index_col[::-1]\n",
        "with open(filename, 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    header = next(reader) #get header\n",
        "    header.insert(0, 'Burst Count') #insert \"Index\" header in the first position\n",
        "    data = [row for row in reader] #get data\n",
        "\n",
        "#create new data with index column\n",
        "new_data = []\n",
        "for i, row in enumerate(data):\n",
        "    row.insert(0, index_col[i])\n",
        "    new_data.append(row)\n",
        "\n",
        "#write data to a new file\n",
        "with open('new_file.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(header)\n",
        "    writer.writerows(new_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "FTUIVtaDeERw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Open the CSV file for reading\n",
        "with open('new_file.csv', 'r') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    data = [row for row in reader]\n",
        "\n",
        "# Round off all floating point values to integers\n",
        "for i, row in enumerate(data):\n",
        "    data[i] = [int(float(cell)) if '.' in cell else cell for cell in row]\n",
        "\n",
        "# Write the updated data back to the same CSV file\n",
        "with open('final.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(data)\n",
        "\n"
      ],
      "metadata": {
        "id": "wQg4s5i5x9jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_string = generate_latex_table(\"new_file.csv\")\n",
        "with open('latex_bursts.tex', 'w') as f:\n",
        "        f.write(table_string)"
      ],
      "metadata": {
        "id": "yjUwWObHz0p3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compute number of parameters by formula**"
      ],
      "metadata": {
        "id": "nIX0x58yJ0Od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Instantiate the ResNet50 model\n",
        "model =  tf.keras.applications.resnet.ResNet50(weights=None) \n",
        "\n",
        "# Define a dictionary to store the number of operations for each layer\n",
        "ops_dict = {}\n",
        "param_dict = {}\n",
        "# Define a function to compute the number of operations for a Conv2D layer\n",
        "def compute_ops_conv2d(layer):\n",
        "    kernel_size = layer.kernel_size[0]\n",
        "    in_channels = layer.input_shape[-1]\n",
        "    out_channels = layer.output_shape[-1]\n",
        "    ops = kernel_size**2 * in_channels * out_channels\n",
        "    return ops\n",
        "\n",
        "# Define a function to compute the number of operations for a MaxPooling2D layer\n",
        "def compute_ops_maxpool2d(layer):\n",
        "    pool_size = layer.pool_size[0]\n",
        "    in_channels = layer.input_shape[-1]\n",
        "    ops = pool_size**2 * in_channels\n",
        "    return ops\n",
        "\n",
        "# Define a function to compute the number of operations for a ReLU layer\n",
        "def compute_ops_relu(layer):\n",
        "    num_elements = tf.reduce_prod(layer.input_shape[1:])\n",
        "    ops = num_elements\n",
        "    return ops\n",
        "\n",
        "# Define a function to compute the number of operations for the output layer\n",
        "def compute_ops_output(layer):\n",
        "    num_input_channels = layer.input_shape[-1]\n",
        "    num_output_channels = layer.output_shape[-1]\n",
        "    fc_ops = (num_input_channels * num_output_channels) + num_output_channels\n",
        "    if type(layer.activation) == tf.keras.activations.softmax or type(layer.activation) ==  tf.keras.activations.sigmoid:\n",
        "        num_elements = tf.reduce_prod(layer.output_shape[1:])\n",
        "        act_ops = num_elements\n",
        "    else:\n",
        "        act_ops = 0\n",
        "    ops = fc_ops + act_ops\n",
        "    return ops\n",
        "\n",
        "# Compute the number of operations for each layer in the model\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "        ops = compute_ops_conv2d(layer)\n",
        "    elif isinstance(layer, tf.keras.layers.MaxPooling2D):\n",
        "        ops = compute_ops_maxpool2d(layer)\n",
        "    elif isinstance(layer, tf.keras.layers.Activation) and type(layer.activation) == tf.keras.activations.relu:\n",
        "        ops = compute_ops_relu(layer)\n",
        "    elif isinstance(layer, tf.keras.layers.Dense):\n",
        "        ops = compute_ops_output(layer)\n",
        "    elif isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "        num_channels = layer.output_shape[-1]\n",
        "        ops = 4 * num_channels\n",
        "    else:\n",
        "        ops = 0\n",
        "    ops_dict[layer.name] = ops\n",
        "    param_dict[layer.name] = layer.count_params()\n",
        "# Print the number of operations for each layer in the model\n",
        "for layer_name, ops in ops_dict.items():\n",
        "    print(layer_name, ops, param_dict[layer_name])\n"
      ],
      "metadata": {
        "id": "Q5IPj3YOEwAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make plot for comparison**"
      ],
      "metadata": {
        "id": "a3Y8rY0a45k8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the csv file into a pandas DataFrame\n",
        "df = pd.read_csv('my_map.csv')\n",
        "\n",
        "# Extract the two columns you need\n",
        "col1 = df['Theoritical']\n",
        "col2 = df['Experimental']\n",
        "\n",
        "# Plot the histogram\n",
        "plt.plot(df.iloc[:43, 1]/1000000, color='blue', label='Theoritical')\n",
        "plt.plot(df.iloc[:43, 2]/1000000, color='red', label='Experimental')\n",
        "\n",
        "# Add a legend and labels for the x and y axes\n",
        "plt.legend()\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('Data (MB)')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aaoQ80nJ4-Y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute computation time"
      ],
      "metadata": {
        "id": "wNLSamFKnlos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Instantiate the ResNet50 model\n",
        "model =  tf.keras.applications.resnet.ResNet50(weights=None) \n",
        "\n",
        "# Print the input and output shape for each convolutional layer in the model\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "      print(layer.name, layer.input_shape, layer.output_shape,  layer.kernel_size, layer.filters)\n",
        "\n",
        "print(len(model.layers))\n"
      ],
      "metadata": {
        "id": "JeLauYSmnr0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Edge : Model\t i9-11900K;\n",
        "#         Cores/Threads\t8/16\n",
        "#         Base Clock\t3.5 GHz\n",
        "#         Boost Clock\t5.3 GHz\n",
        "#         Cache\t  16 MB\n",
        "#         TDP\t  125W\n",
        "#         GFLOPs  925.6\n",
        "\n",
        "# Raspberry Pi 4 \n",
        "# GFLOPs 24 \n",
        "# Memory 1 to 8 GB\n",
        "\n",
        "\n",
        "Edge = 925\n",
        "CE = 0\n",
        "\n",
        "# Near the Edge : Model Intel Xeon E5-2666 v3\t\n",
        "# c4.16xlarge\tvCPUs 64\tGFLOPs 2144.0 \t$1.75/\n",
        "# c4.8xlarge\tvCPUs 36\tMemory 60 GiB\tEBS only\tOn Demand $1.59/hr\tReserved $1.01/hr\t\n",
        "# c4.large\tvCPUs 2\tMemory 3.75 GiB\tEBS only\tOn Demand $0.10/hr\tReserved $0.06/hr\tGFLOPs 67.2\n",
        "\n",
        "# c7g\n",
        "\n",
        "NTE = 3500\n",
        "CNTE = 1.59/3600 # cost per second\n",
        "\n",
        "# Cloud : inf1.24xlarge\t8x AWS Inferentia chips with 16 Neuron Cores each\t\n",
        "#  Memory 192 (GiB)\tTFLOPs\t42.0\n",
        "# inf1.24xlarge\tvCPUs 96\tNetwork b/w\t100\tEBS b/w 19\t$4.721/Hr\n",
        "# inf1.xlarge\tvCPUs 4\tMemory 8 GiB\tEBS only\tOn Demand $0.23/hr\tReserved $0.14/hr GFLOPs = 2250\n",
        "# inf2.48xlarge\tvCPUs 192\tMemory 768 GiB\tEBS only\tOn Demand $12.98/hr\tReserved $8.18/hr GFLOPs = 8,400,000\n",
        "\n",
        "# T4 GPU 65 TFLOPs\n",
        "Cloud = 65000\n",
        "# CC = 2.74/3600  # cost per second\n",
        "CC = 4.352/3600  # cost per second\n",
        "\n",
        "\n",
        "# cost model from Bell Network charges $0.3078 for transferring 1GB over its OC3 link -> 150 Mbps\n",
        "TCost = 307.8 # per MB\n",
        "# print(f'Cost for transmission : ${params/TCost}')"
      ],
      "metadata": {
        "id": "2LDMdbGpkYlt"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.api._v2.keras.layers import Activation\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Instantiate the ResNet50 model\n",
        "model =  tf.keras.applications.resnet.ResNet50(weights=None) \n",
        "# model = tf.keras.applications.vgg16.VGG16(weights=None) \n",
        "# model =  tf.keras.applications.resnet.ResNet152(weights='imagenet') \n",
        "# model =  tf.keras.applications.InceptionResNetV2(weights=None) \n",
        "# model.summary()\n",
        "\n",
        "# # Define the input shape of the model\n",
        "# input_shape = model.input_shape[1:]\n",
        "\n",
        "# # Generate a random image with the input shape of the model\n",
        "# random_image = np.random.rand(*input_shape)\n",
        "\n",
        "# # Preprocess the image\n",
        "# preprocessed_image = tf.keras.applications.resnet50.preprocess_input(random_image)\n",
        "\n",
        "# # Make a prediction with the model\n",
        "# prediction = model.predict(np.array([preprocessed_image]))\n",
        "\n",
        "# # Decode the prediction\n",
        "# decoded_prediction = tf.keras.applications.resnet50.decode_predictions(prediction, top=1)[0][0]\n",
        "\n",
        "# # Print the decoded prediction\n",
        "# print(decoded_prediction)\n",
        "\n",
        "# Define a dictionary to store the number of operations for each layer\n",
        "ops_dict = {}\n",
        "\n",
        "batch_size = 1\n",
        "# model_input_shape = (batch_size, 224, 224, 3)\n",
        "\n",
        "# Define a function to compute the number of operations for a Conv2D layer\n",
        "def compute_ops_conv2d(layer):\n",
        "    kernel_size = layer.kernel_size[0]\n",
        "    in_channels = layer.input_shape[-1]\n",
        "    out_channels = layer.output_shape[-1]\n",
        "    input_height, input_width = layer.input_shape[1:3]\n",
        "    output_height, output_width = layer.output_shape[1:3]\n",
        "    ops = kernel_size**2 * in_channels * output_height * output_width * out_channels\n",
        "    return ops * batch_size\n",
        "\n",
        "# Define a function to compute the number of operations for a MaxPooling2D layer\n",
        "def compute_ops_maxpool2d(layer):\n",
        "    pool_size = layer.pool_size[0]\n",
        "    in_channels = layer.input_shape[-1]\n",
        "    input_height, input_width = layer.input_shape[1:3]\n",
        "    output_height, output_width = layer.output_shape[1:3]\n",
        "    ops = pool_size**2 * in_channels * output_height * output_width\n",
        "    return ops * batch_size\n",
        "\n",
        "# Define a function to compute the number of operations for a BatchNormalization layer\n",
        "def compute_ops_batchnorm(layer):\n",
        "    # Get input shape\n",
        "    input_shape = layer.input_shape[1:]\n",
        "    in_channels = input_shape[-1]\n",
        "\n",
        "    # Number of operations per element (2 for mean and variance)\n",
        "    ops = 2 * in_channels\n",
        "\n",
        "    return ops * batch_size\n",
        "\n",
        "# Define a function to compute the number of operations for a ReLU layer\n",
        "def compute_ops_relu(layer):\n",
        "\n",
        "    input_shape = layer.input_shape[1:]\n",
        "    # Number of operations per element\n",
        "    ops = 1\n",
        "    for dim in input_shape:\n",
        "        ops *= dim\n",
        "\n",
        "    return ops * batch_size\n",
        "\n",
        "# Define a function to compute the number of operations for the output layer\n",
        "def compute_ops_output(layer):\n",
        "    num_input_channels = layer.input_shape[-1]\n",
        "    num_output_channels = layer.output_shape[-1]\n",
        "    fc_ops = (num_input_channels * num_output_channels) + num_output_channels\n",
        "    if type(layer.activation) == tf.keras.activations.softmax or type(layer.activation) == tf.keras.activations.sigmoid:\n",
        "        num_elements = tf.reduce_prod(layer.output_shape[1:])\n",
        "        act_ops = num_elements\n",
        "    else:\n",
        "        act_ops = 0\n",
        "    ops = fc_ops + act_ops\n",
        "    return ops * batch_size\n",
        "\n",
        "# Print the number of operations for each layer in the model\n",
        "sum = 0;\n",
        "\n",
        "\n",
        "# Compute the number of operations for each layer in the model\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "        ops = compute_ops_conv2d(layer)\n",
        "    elif isinstance(layer, tf.keras.layers.MaxPooling2D):\n",
        "        ops = compute_ops_maxpool2d(layer)\n",
        "    elif isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "        ops = compute_ops_batchnorm(layer)\n",
        "    elif isinstance(layer, tf.keras.layers.Activation):\n",
        "        ops = compute_ops_relu(layer)\n",
        "    elif isinstance(layer, tf.keras.layers.Dense):\n",
        "        ops = compute_ops_output(layer)\n",
        "    else:\n",
        "        ops = 0\n",
        "    ops_dict[layer.name] = [ops,layer.input_shape, layer.output_shape]\n",
        "    # print(layer.name, ops, layer.input_shape)\n",
        "\n",
        "i = 0\n",
        "for layer_name, (ops, inp, out) in ops_dict.items():\n",
        "    sum = sum + ops\n",
        "    inp_size = 0\n",
        "\n",
        "    if inp[0] is not None:\n",
        "      (n,l,h,w) = inp[0]\n",
        "      inp_size += l*h*w*batch_size/1000000\n",
        "      \n",
        "      if len(inp) == 2:\n",
        "        (n,l,h,w) = inp[1]\n",
        "        inp_size += l*h*w*batch_size/1000000\n",
        "\n",
        "    elif len(inp) > 2:\n",
        "      inp_size += inp[1]*inp[2] * inp[3] * batch_size/1000000\n",
        "    else:\n",
        "      inp_size += inp[1] * batch_size/1000000\n",
        "\n",
        "    if i == 0:\n",
        "      (n,l,h,w) = inp[0]\n",
        "      i = i+10\n",
        "      params = l*h*w\n",
        "    # print(layer_name, ops, inp_size)\n",
        "\n",
        "\n",
        "\n",
        "sum = sum/1000000000 #GFLOP\n",
        "GFLOPs = sum\n",
        "param = params/1000000\n",
        "print(f'input image : {params}')\n",
        "arr_GFLOP = []\n",
        "arr_input = []\n",
        "total_cost = []\n",
        "total_time = []\n",
        "for batch_size in [1,32,64,128]:\n",
        "  params = param * batch_size \n",
        "  GFLOP = GFLOPs * batch_size\n",
        "  # print(f'GFLOP : {GFLOP * batch_size}')\n",
        "  # print(f'Total input images : {params * batch_size} MB')\n",
        "  # print()\n",
        "\n",
        "  arr_GFLOP.append(GFLOP)\n",
        "  arr_input.append(params)\n",
        "\n",
        "  # Bandwidth = 20 mbps \n",
        "  # Transmission time from E to NTE\n",
        "  BWENTE = 20\n",
        "  TENTE = params/BWENTE\n",
        "\n",
        "  PENTE = 0.001 # 1 ms\n",
        "  PNTEC = 0.1 # 100 ms\n",
        "  # print(f'Transmission Time from Edge to Near the Edge : {TENTE} sec')\n",
        "\n",
        "  # print(f'Propagation Delay from Edge to Near the Edge : {PENTE} sec')\n",
        "\n",
        "\n",
        "\n",
        "  # Bandwidth = 20 Mbps\n",
        "  # Transmission time from E to Cloud\n",
        "  BWNTEC = 20\n",
        "  TNTEC = params/BWNTEC\n",
        "\n",
        "  # print(f'Transmission Time from Near the Edge to Cloud : {TNTEC} sec')\n",
        "  # print(f'Propagation Delay from Near the Edge to Cloud: {PNTEC} sec')\n",
        "\n",
        "  TEC = TENTE + TNTEC\n",
        "  PEC = PENTE + PNTEC\n",
        "  # print(f'Transmission Time from Edge to Cloud : {TEC} sec')\n",
        "  # print(f'Propagation Delay from Edge to Cloud: {PEC} sec')\n",
        "\n",
        "  TE = GFLOP / Edge\n",
        "  TNTE = GFLOP / NTE\n",
        "  TC = GFLOP / Cloud\n",
        "\n",
        "  # print(f'Time for excecution at Edge : {TE} secs')\n",
        "  # print(f'Time for excecution at NTE : {TNTE} secs')\n",
        "  # print(f'Time for excecution at Cloud : {TC} secs')\n",
        "\n",
        "  # print()\n",
        "\n",
        "  # print(f'Transmission Time from Edge to Near the Edge : {TENTE} sec')\n",
        "  # print(f'Transmission Time from Edge to Cloud : {TEC} sec')\n",
        "  # print()\n",
        "\n",
        "  # print(f'Total time at Near the Edge : {TNTE + TENTE + PENTE} sec')\n",
        "  # print(f'Total time at Cloud : {TEC + TC + PEC} sec')\n",
        "\n",
        "  time = []\n",
        "  time.append(TE)\n",
        "  time.append(TNTE + TENTE + PENTE)\n",
        "  time.append(TEC + TC + PEC)\n",
        "  total_time.append(time)\n",
        "  cost = []\n",
        "  MCE = TE * CE\n",
        "  MCNTE = TNTE * CNTE \n",
        "  MCC = TC * CC\n",
        "  cost.append(MCE)\n",
        "  cost.append(MCNTE)\n",
        "  cost.append(MCC)\n",
        "  total_cost.append(cost)\n",
        "  # print()\n",
        "  # print(f'Cost for excecution at Edge : ${MCE}')\n",
        "  # print(f'Cost for excecution at NTE : ${MCNTE}')\n",
        "  # print(f'Cost for excecution at Cloud : ${MCC}')\n",
        "  # print(f'Parameters Memory : 102 MB')\n"
      ],
      "metadata": {
        "id": "1b1o-QJFKJZv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aa9f2df-be54-4340-dafa-310c1cd06d4c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input image : 150528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv  \n",
        "with open(\"store_costs.csv\", \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"Batch Size\",\"Computation complexity(GFLOP)\", \"Input Size (MB)\", \"Total time at Edge\", \"Total time at Near the Edge\", \"Total time at Cloud\",  \"Total cost at Edge\", \"Total cost at Near the Edge\", \"Total cost at Cloud\"])\n",
        "    i=0\n",
        "    for batch_size in [1,32,64,128]:\n",
        "      writer.writerow([batch_size,arr_GFLOP[i],arr_input[i],total_time[i][0],total_time[i][1],total_time[i][2],total_cost[i][0],total_cost[i][1], total_cost[i][2]])\n",
        "      i += 1\n",
        "# print(total_time[0][3])"
      ],
      "metadata": {
        "id": "_nzYxsvd0pSG"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bandwidth = 1 Gbps \n",
        "# Transmission time from E to NTE\n",
        "BWENTE = 20\n",
        "TENTE = params/BWENTE\n",
        "\n",
        "PENTE = 0.001 # 1 ms\n",
        "PNTEC = 0.1 # 100 ms\n",
        "print(f'Transmission Time from Edge to Near the Edge : {TENTE} sec')\n",
        "\n",
        "print(f'Propagation Delay from Edge to Near the Edge : {PENTE} sec')\n",
        "\n",
        "\n",
        "\n",
        "# Bandwidth = 20 Mbps\n",
        "# Transmission time from E to Cloud\n",
        "BWNTEC = 20\n",
        "TNTEC = params/BWNTEC\n",
        "\n",
        "print(f'Transmission Time from Near the Edge to Cloud : {TNTEC} sec')\n",
        "print(f'Propagation Delay from Near the Edge to Cloud: {PNTEC} sec')\n",
        "\n",
        "TEC = TENTE + TNTEC\n",
        "PEC = PENTE + PNTEC\n",
        "print(f'Transmission Time from Edge to Cloud : {TEC} sec')\n",
        "print(f'Propagation Delay from Edge to Cloud: {PEC} sec')\n",
        "\n",
        "TE = GFLOP / Edge\n",
        "TNTE = GFLOP / NTE\n",
        "TC = GFLOP / Cloud\n",
        "\n",
        "print(f'Time for excecution at Edge : {TE} secs')\n",
        "print(f'Time for excecution at NTE : {TNTE} secs')\n",
        "print(f'Time for excecution at Cloud : {TC} secs')\n",
        "\n",
        "print()\n",
        "\n",
        "print(f'Transmission Time from Edge to Near the Edge : {TENTE} sec')\n",
        "print(f'Transmission Time from Edge to Cloud : {TEC} sec')\n",
        "print()\n",
        "\n",
        "print(f'Total time at Near the Edge : {TNTE + TENTE + PENTE} sec')\n",
        "print(f'Total time at Cloud : {TEC + TC + PEC} sec')\n",
        "\n",
        "MCE = TE * CE\n",
        "MCNTE = TNTE * CNTE \n",
        "MCC = TC * CC\n",
        "print()\n",
        "print(f'Cost for excecution at Edge : ${MCE}')\n",
        "print(f'Cost for excecution at NTE : ${MCNTE}')\n",
        "print(f'Cost for excecution at Cloud : ${MCC}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLLJGDcjyOL1",
        "outputId": "b78ccc84-d832-4229-dbd3-faf182a610bd"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transmission Time from Edge to Near the Edge : 0.9633792 sec\n",
            "Propagation Delay from Edge to Near the Edge : 0.001 sec\n",
            "Transmission Time from Near the Edge to Cloud : 0.9633792 sec\n",
            "Propagation Delay from Near the Edge to Cloud: 0.1 sec\n",
            "Transmission Time from Edge to Cloud : 1.9267584 sec\n",
            "Propagation Delay from Edge to Cloud: 0.101 sec\n",
            "Time for excecution at Edge : 0.5353742612756757 secs\n",
            "Time for excecution at NTE : 0.386891556 secs\n",
            "Time for excecution at Cloud : 0.007618787564307693 secs\n",
            "\n",
            "Transmission Time from Edge to Near the Edge : 0.9633792 sec\n",
            "Transmission Time from Edge to Cloud : 1.9267584 sec\n",
            "\n",
            "Total time at Near the Edge : 1.351270756 sec\n",
            "Total time at Cloud : 2.0353771875643076 sec\n",
            "\n",
            "Cost for excecution at Edge : $0.0\n",
            "Cost for excecution at NTE : $0.00010854457543333333\n",
            "Cost for excecution at Cloud : $5.798743868389744e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Memory required by ResNet152 = 242 MB (parameter) + 200 KB ( for intermediate activations)\n",
        "Mem = 242 # MB"
      ],
      "metadata": {
        "id": "Mw34lmFxQenG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT2 Model"
      ],
      "metadata": {
        "id": "iQ4Bk6LlJr87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers\n",
        "\n",
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2Model.from_pretrained('gpt2')\n",
        "text = \"Replace me by any text you'd like.\"\n",
        "encoded_input = tokenizer(text, return_tensors='pt')\n",
        "output = model(**encoded_input)\n",
        "# print(len(model.layers))"
      ],
      "metadata": {
        "id": "wRCmVwOr3NUs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if 'weight' in name:\n",
        "        print(f'Layer: {name}, Shape: {param.shape}')"
      ],
      "metadata": {
        "id": "qmA5IWx84Lkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import GPT2Model\n",
        "\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "\n",
        "# Define the GPT-2 model\n",
        "model = GPT2Model.from_pretrained('gpt2')\n",
        "\n",
        "# Define the input\n",
        "input_ids = torch.randint(0, 1000, (1, 128))\n",
        "\n",
        "# Define the profiler\n",
        "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
        "    # Run the model\n",
        "    with record_function(\"model_inference\"):\n",
        "        with torch.no_grad():\n",
        "            output = model(input_ids)\n",
        "\n",
        "# Print the profiler results\n",
        "print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"self_cpu_time_total\", row_limit=10))\n"
      ],
      "metadata": {
        "id": "rQLVffYW7Tts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchprofile import profile_macs\n",
        "from torchsummary import summary\n",
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "\n",
        "# Load the model\n",
        "# model = GPT2Model.from_pretrained('gpt2')\n",
        "\n",
        "# Create a sample input\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "input_str = 'Hello, how are you today?'\n",
        "input_ids = torch.tensor([tokenizer.encode(input_str)])\n",
        "\n",
        "# Compute the FLOPs of each layer in the model\n",
        "macs_list = [profile_macs(layer, (input_ids,)) for layer in model.modules()]\n",
        "for i, macs in enumerate(macs_list):\n",
        "    if macs is not None:\n",
        "        print(f\"Layer {i + 1} FLOPs: {macs}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "RFo0_i7372hK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2Model\n",
        "from torchprofile import profile_macs\n",
        "\n",
        "# define the model and input\n",
        "# model = GPT2Model.from_pretrained('gpt2')\n",
        "# input_ids = torch.randint(low=0, high=1000, size=(1, 512))\n",
        "\n",
        "# compute the FLOPs of each layer in the model\n",
        "macs_list = {}\n",
        "for module in model.modules():\n",
        "    if hasattr(module, 'forward') and module.forward.__code__.co_argcount > 1:\n",
        "        macs_list.append(profile_macs(module, (input_ids,)))\n",
        "\n",
        "\n",
        "for i, macs in enumerate(macs_list):\n",
        "    print(f\"Layer {i + 1} FLOPs: {macs}\")\n"
      ],
      "metadata": {
        "id": "0FEzd7w089eP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install thop\n",
        "# !pip nstall transformers\n",
        "import torch\n",
        "from transformers import GPT2Model\n",
        "from thop import profile\n",
        "from torchsummary import summary\n",
        "\n",
        "# define the model and input\n",
        "# model = GPT2Model.from_pretrained('gpt2')\n",
        "input_ids = torch.randint(low=0, high=1000, size=(1, 512))\n",
        "# summary(model, [(1, 512)])\n",
        "# compute the FLOPs of each layer in the model\n",
        "flops_list = []\n",
        "for name, module in model.named_modules():\n",
        "    if isinstance(module, torch.nn.Linear) or isinstance(module, torch.nn.MultiheadAttention):\n",
        "        input_size = (input_ids.size(0),) + tuple(module.in_proj_weight.shape[1:])\n",
        "        flops, params = profile(module, inputs=(input_ids,), verbose=False)\n",
        "        flops_list.append((name, flops))\n",
        "        \n",
        "for i, (name, flops) in enumerate(flops_list):\n",
        "    print(f\"Layer {i + 1} ({name}) FLOPs: {flops}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "vBnefpVFIVTI",
        "outputId": "9a873d33-36dc-44de-815b-156b4bf7e343"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-a68eb7f244b7>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# model = GPT2Model.from_pretrained('gpt2')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m# compute the FLOPs of each layer in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mflops_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m         \u001b[0mposition_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwpe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposition_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1538\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1539\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m             for hook_id, hook in (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2208\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2209\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard\n"
      ],
      "metadata": {
        "id": "6xRYO57qAzOY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import plot_model\n",
        "from datetime import datetime\n",
        "\n",
        "# Set up log directory for TensorBoard\n",
        "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "# Define a Keras callback for TensorBoard\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "# Plot the model graph and save as image file\n",
        "plot_model(model, to_file='resnet50.png')\n",
        "\n",
        "# Launch TensorBoard\n",
        "!tensorboard --logdir logs\n"
      ],
      "metadata": {
        "id": "490qctxTBcSt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc586451-193b-4ac5-97e7-7cfafcf93b65"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-05 17:00:41.145573: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.33' not found (required by /usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server)\n",
            "/usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.34' not found (required by /usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server)\n",
            "/usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.32' not found (required by /usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server)\n",
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.12.2 at http://localhost:6006/ (Press CTRL+C to quit)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding Model Summary"
      ],
      "metadata": {
        "id": "lMga9u2O_6BF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# model = tf.keras.applications.resnet.ResNet50(weights='imagenet');\n",
        "# model =  tf.keras.applications.InceptionResNetV2(weights=None) \n",
        "# model.summary();\n",
        "print(len(model.layers))\n",
        "trainableLayerNameList = [layer.name for layer in model.layers if layer.trainable_variables]\n",
        "# print(len(trainableLayerNameList));"
      ],
      "metadata": {
        "id": "_KhiPXEdPTXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6bb52c1-0b70-4cbf-d889-5d596c45487c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainable = 0\n",
        "\n",
        "# iterate over the layers in the model\n",
        "for layer in model.layers:\n",
        "    # check if the layer has trainable parameters\n",
        "    if layer.trainable_variables:\n",
        "        # if the layer has trainable parameters, increment the counter\n",
        "        trainable += 1\n",
        "\n",
        "# print the number of layers involved in the AllReduce operation\n",
        "print(f'Number of layers with trainable parameters: {trainable}')"
      ],
      "metadata": {
        "id": "ybE7ry0qP1pz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ed9d609-c4cd-4b71-e318-840ef9ff71c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of layers with trainable parameters: 107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "allreduce_layers = 0;\n",
        "for layer in model.layers:\n",
        "    # check if the layer has trainable parameters\n",
        "    if not layer.trainable_variables:\n",
        "        # if the layer has trainable parameters, increment the counter\n",
        "        if \"add\" in layer.name:\n",
        "          allreduce_layers += 1\n",
        "          \n",
        "# print the number of layers involved in the AllReduce operation\n",
        "print(f'Number of layers not involved in AllReduce: {allreduce_layers}')\n",
        "print(f'Number of layers involved in AllReduce: {len(model.layers) - allreduce_layers}')"
      ],
      "metadata": {
        "id": "gCohVvkkRyF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "resnet101 = tf.keras.applications.resnet.ResNet101(weights='imagenet')\n",
        "len(resnet101.layers)\n",
        "trainableLayerNameList = [layer.name for layer in resnet101.layers if layer.trainable_variables]\n",
        "print(len(trainableLayerNameList));\n",
        "allreduce_layers = 0;\n",
        "for layer in resnet101.layers:\n",
        "    # check if the layer has trainable parameters\n",
        "    if not layer.trainable_variables:\n",
        "        if \"add\" in layer.name:\n",
        "          allreduce_layers += 1\n",
        "          # print(layer.name);\n",
        "print(f'Number of layers not involved in AllReduce: {allreduce_layers}')"
      ],
      "metadata": {
        "id": "YQ-t2GJ_gcZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16 = tf.keras.applications.vgg16.VGG16(weights=None)\n",
        "vgg16.summary();\n",
        "print(f'Number of layers : {len(vgg16.layers)}')\n",
        "trainableLayerNameList = [layer.name for layer in vgg16.layers if layer.trainable_variables]\n",
        "# print(len(trainableLayerNameList));\n",
        "allreduce_layers = 0;\n",
        "for layer in vgg16.layers:\n",
        "    # check if the layer has trainable parameters\n",
        "    if not layer.trainable_variables:\n",
        "        if \"add\" in layer.name:\n",
        "          allreduce_layers += 1\n",
        "          # print(layer.name);\n",
        "print(f'Number of layers not involved in AllReduce: {allreduce_layers}')"
      ],
      "metadata": {
        "id": "5Yla5IXykM7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "conv2d = 0;\n",
        "for layer in vgg16.layers:\n",
        "  if \"_conv\" in layer.name:\n",
        "    conv2d += 1;\n",
        "print(conv2d);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFoMUcturFkA",
        "outputId": "b2bf6d59-6d63-4122-bfa0-1d3d8a260f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainableLayerNameList)"
      ],
      "metadata": {
        "id": "zynCYzoFy_VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DNN Computational Graph Visualization"
      ],
      "metadata": {
        "id": "9QWBcOWJg5k-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchviz\n",
        "import torch\n",
        "import torchviz\n",
        "import torchvision.models as models\n",
        "\n",
        "# Load the ResNet50 model\n",
        "resnet = models.resnet50(pretrained=False)\n",
        "\n",
        "# Create a random input tensor\n",
        "x = torch.randn(1, 3, 224, 224)\n",
        "\n",
        "# Generate the output tensor and the computational graph\n",
        "y = resnet(x)\n",
        "dot = torchviz.make_dot(y, params=dict(resnet.named_parameters()))\n",
        "\n",
        "# Save the graph to a PDF file\n",
        "dot.render('resnet50_graph')\n",
        "\n",
        "# Display the graph in Jupyter notebook (optional)\n",
        "# dot\n"
      ],
      "metadata": {
        "id": "wQ6dU7tIZfRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchviz\n",
        "\n",
        "# Load the ResNet50 model\n",
        "resnet = torch.hub.load('pytorch/vision', 'resnet50', pretrained=False)\n",
        "\n",
        "# Create a random input tensor\n",
        "x = torch.randn(1, 3, 224, 224)\n",
        "\n",
        "# Generate the output tensor and the computational graph\n",
        "y = resnet(x)\n",
        "graph = torchviz.make_dot(y, params=dict(resnet.named_parameters()))\n",
        "\n",
        "# Get the input size for each layer\n",
        "input_sizes = {}\n",
        "for name, module in resnet.named_modules():\n",
        "    if isinstance(module, nn.Conv2d):\n",
        "        input_sizes[name] = x.shape[2:]\n",
        "    elif isinstance(module, nn.MaxPool2d):\n",
        "        x = module(x)\n",
        "        input_sizes[name] = x.shape[2:]\n",
        "\n",
        "# Print the input size for each layer\n",
        "for name, size in input_sizes.items():\n",
        "    print(f\"{name}: {size}\")\n",
        "\n",
        "# Save the graph in a PDF file\n",
        "graph.render(\"resnet50_graph\")\n"
      ],
      "metadata": {
        "id": "OZ10yoYzpFgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchviz\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import torchviz\n",
        "import pydot\n",
        "\n",
        "# Load the ResNet50 model\n",
        "model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False)\n",
        "\n",
        "# model = tf.keras.applications.vgg16.VGG16(weights=None) \n",
        "# model =  tf.keras.applications.resnet.ResNet152(weights='imagenet', include_top=False) \n",
        "model =  tf.keras.applications.InceptionResNetV2(weights=None) \n",
        "\n",
        "# Convert the model summary to a PyDot graph\n",
        "dot = tf.keras.utils.model_to_dot(model)\n",
        "\n",
        "# Convert the PyDot graph to a PDF file\n",
        "pdf_bytes = dot.create_pdf()\n",
        "# with open('resnet50.pdf', 'wb') as f:\n",
        "# with open('vgg16.pdf', 'wb') as f:\n",
        "with open('InceptionResNetV2.pdf', 'wb') as f:\n",
        "    f.write(pdf_bytes)\n"
      ],
      "metadata": {
        "id": "jxFBFOyKg3Wn"
      },
      "execution_count": 68,
      "outputs": []
    }
  ]
}