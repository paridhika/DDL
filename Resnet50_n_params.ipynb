{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paridhika/DDL/blob/main/Resnet50_n_params.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# According to PyTorch"
      ],
      "metadata": {
        "id": "uN3qotb__Mq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "from torchvision.models import resnet50\n",
        "import torch\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "ETJGbo7g_IqW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(resnet50(), (3, 224, 224))"
      ],
      "metadata": {
        "id": "E0MxyiMD_WVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# According to TF"
      ],
      "metadata": {
        "id": "HZGYh8Sd_cG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "_DfmwWFc_v6H"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.applications.resnet.ResNet50(weights=None)\n",
        "# model.summary();"
      ],
      "metadata": {
        "id": "FIvEneg__xM8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get layers with tensors"
      ],
      "metadata": {
        "id": "Es2EGNx0Y4Ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.math_ops import sub\n",
        "# import tensorflow as tf\n",
        "# model = tf.keras.applications.resnet.ResNet50(weights='imagenet');\n",
        "# model.summary();\n",
        "import csv  \n",
        "layer_count = 0\n",
        "my_map = {}\n",
        "for i, layer in enumerate(model.layers):\n",
        "    if \"add\" not in layer.name:\n",
        "        layer_count += 1\n",
        "        # print(\"Layer {}: {} ({} parameters)\".format(layer_count, layer.name, layer.count_params()))\n",
        "        my_map[layer.name] = layer.count_params()\n",
        "  \n",
        "print(len(my_map))\n",
        "\n",
        "map_list = list(my_map.items())\n",
        "map_list.reverse()\n",
        "with open(\"tensor_layers.csv\", \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(map_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH8P5T57Y_Eb",
        "outputId": "c91ec407-7abe-46a3-964a-f24eb96921ce"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get layers with parameters"
      ],
      "metadata": {
        "id": "RO7kxoucZxRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.math_ops import sub\n",
        "# import tensorflow as tf\n",
        "# model = tf.keras.applications.resnet.ResNet50(weights='imagenet');\n",
        "# model.summary();\n",
        "import csv  \n",
        "layer_count = 0\n",
        "my_map = {}\n",
        "for i, layer in enumerate(model.layers):\n",
        "    if len(layer.weights) > 0:\n",
        "      if \"add\" not in layer.name:\n",
        "        layer_count += 1\n",
        "        # print(\"Layer {}: {} ({} parameters)\".format(layer_count, layer.name, layer.count_params()))\n",
        "        my_map[layer.name] = layer.count_params()\n",
        "  \n",
        "print(len(my_map))\n",
        "\n",
        "map_list = list(my_map.items())\n",
        "map_list.reverse()\n",
        "with open(\"parameters_layers.csv\", \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(map_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaKp_Oo3Z0oi",
        "outputId": "bbe350b7-6d58-4549-810a-105b9f8bc16a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute burst size"
      ],
      "metadata": {
        "id": "0OokMaVYPjXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.math_ops import sub\n",
        "# import tensorflow as tf\n",
        "# model = tf.keras.applications.resnet.ResNet50(weights='imagenet');\n",
        "# model.summary();\n",
        "import csv  \n",
        "layer_count = 0\n",
        "substring = \"\"\n",
        "my_map = {}\n",
        "\n",
        "\n",
        "for i, layer in enumerate(model.layers):\n",
        "    if len(layer.weights) > 0:\n",
        "      if \"_\" in layer.name:\n",
        "        layer_count += 1\n",
        "        # print(\"Layer {}: {} ({} parameters)\".format(layer_count, layer.name, layer.count_params()))\n",
        "        substring = layer.name[:layer.name.rindex(\"_\")]\n",
        "        if substring in my_map:\n",
        "          my_map[substring] = my_map[substring] + layer.count_params()\n",
        "        else:\n",
        "          my_map[substring] = layer.count_params()\n",
        "      else:\n",
        "        my_map[layer.name] = layer.count_params()\n",
        "  \n",
        "print(len(my_map))\n",
        "my_map[\"Layer Name\"] = \"Theoritical\"\n",
        "map_list = list(my_map.items())\n",
        "map_list.reverse()\n",
        "with open(\"my_map.csv\", \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(map_list)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtXakP2APrc2",
        "outputId": "6441dc01-d29e-4f58-c04a-0fac620d13af"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get table of comparison between theoritical and experimental burst sizes**"
      ],
      "metadata": {
        "id": "jjI6pNG5g_Ut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "def generate_latex_table(filename):\n",
        "    with open(filename, newline='') as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "        header = next(reader)\n",
        "        table = []\n",
        "        for row in reader:\n",
        "            table.append(row)\n",
        "        \n",
        "    table_string = \"\\\\begin{tabular}{|\" + \"c|\"*len(header) + \"}\\n\\\\hline\\n\"\n",
        "    table_string += \" & \".join(header) + \"\\\\\\\\\\n\\\\hline\\n\"\n",
        "    for row in table:\n",
        "        table_string += \" & \".join(row) + \"\\\\\\\\\\n\\\\hline\\n\"\n",
        "    table_string += \"\\\\end{tabular}\"\n",
        "    \n",
        "    return table_string\n",
        "\n",
        "numbers = [2049839.5,1048383.5,2359135.5,1048447.5,1048367.5,2359167.5,1048367.5,1048367.5,2096959.5,2359311.5,524079.5,262015.5,589647.5,261983.5,261951.5,589695.5,261951.5,262015.5,589615.5,261935.5,261935.5,589663.5,262015.5,262527.5,589615.5,261919.5,261935.5,524143.5,589599.5,130943.5,65359.5,147231.5,65375.5,65551.5,147247.5,65343.5,65391.5,147231.5,65327.5,65551.5,130879.5,147231.5,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "rounded_values = [int(round(number)) for number in numbers]\n",
        "\n",
        "# Load the existing CSV file into a pandas dataframe\n",
        "df = pd.read_csv(\"my_map.csv\")\n",
        "\n",
        "# Create a new column in the dataframe with the rounded integer values\n",
        "df[\"Experimental\"] = rounded_values\n",
        "\n",
        "# Save the updated dataframe to the existing CSV file\n",
        "df.to_csv(\"my_map.csv\", index=False)\n",
        "\n",
        "filename = 'my_map.csv'\n",
        "index_col = [i for i in range(1, 55)] #index column\n",
        "index_col = index_col[::-1]\n",
        "with open(filename, 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    header = next(reader) #get header\n",
        "    header.insert(0, 'Burst Count') #insert \"Index\" header in the first position\n",
        "    data = [row for row in reader] #get data\n",
        "\n",
        "#create new data with index column\n",
        "new_data = []\n",
        "for i, row in enumerate(data):\n",
        "    row.insert(0, index_col[i])\n",
        "    new_data.append(row)\n",
        "\n",
        "#write data to a new file\n",
        "with open('new_file.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(header)\n",
        "    writer.writerows(new_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "FTUIVtaDeERw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Open the CSV file for reading\n",
        "with open('new_file.csv', 'r') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    data = [row for row in reader]\n",
        "\n",
        "# Round off all floating point values to integers\n",
        "for i, row in enumerate(data):\n",
        "    data[i] = [int(float(cell)) if '.' in cell else cell for cell in row]\n",
        "\n",
        "# Write the updated data back to the same CSV file\n",
        "with open('final.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(data)\n",
        "\n"
      ],
      "metadata": {
        "id": "wQg4s5i5x9jq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_string = generate_latex_table(\"new_file.csv\")\n",
        "with open('latex_bursts.tex', 'w') as f:\n",
        "        f.write(table_string)"
      ],
      "metadata": {
        "id": "yjUwWObHz0p3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make plot for comparison**"
      ],
      "metadata": {
        "id": "a3Y8rY0a45k8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the csv file into a pandas DataFrame\n",
        "df = pd.read_csv('my_map.csv')\n",
        "\n",
        "# Extract the two columns you need\n",
        "col1 = df['Theoritical']\n",
        "col2 = df['Experimental']\n",
        "\n",
        "# Plot the histogram\n",
        "plt.plot(df.iloc[:43, 1]/1000000, color='blue', label='Theoritical')\n",
        "plt.plot(df.iloc[:43, 2]/1000000, color='red', label='Experimental')\n",
        "\n",
        "# Add a legend and labels for the x and y axes\n",
        "plt.legend()\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('Data (MB)')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aaoQ80nJ4-Y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute computation time"
      ],
      "metadata": {
        "id": "wNLSamFKnlos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "\n",
        "# # Define your ResNet50 model\n",
        "# model = tf.keras.applications.ResNet50(weights='imagenet')\n",
        "import time\n",
        "\n",
        "# Create an example input tensor\n",
        "input_tensor = tf.random.normal([1,224,224,3])\n",
        "\n",
        "# Record the start time\n",
        "start = time.time()\n",
        "\n",
        "# Perform a forward pass through the model\n",
        "output = model(input_tensor)\n",
        "\n",
        "# Record the end time\n",
        "end = time.time()\n",
        "\n",
        "# Calculate the total computation time\n",
        "total_time = end - start\n",
        "\n",
        "print(\"Total computation time:\", total_time, \"seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "JeLauYSmnr0U",
        "outputId": "0c0c1bb2-2457-418d-c29c-df83b27fb823"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ab531e2d4494>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Perform a forward pass through the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Record the end time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import requests\n",
        "import tarfile\n",
        "\n",
        "# URL to download the ImageNet dataset from\n",
        "url = \"http://www.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_train.tar\"\n",
        "\n",
        "# File name for the ImageNet dataset\n",
        "file_name = \"ILSVRC2012_img_train.tar\"\n",
        "\n",
        "# Download the ImageNet dataset\n",
        "try:\n",
        "    response = requests.get(url)\n",
        "    open(file_name, \"wb\").write(response.content)\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(\"Failed to download ImageNet dataset:\", e)\n",
        "    exit()\n",
        "\n",
        "# Extract the ImageNet dataset\n",
        "try:\n",
        "    with tarfile.open(file_name, \"r\") as f:\n",
        "        f.extractall(\"imagenet\")\n",
        "except Exception as e:\n",
        "    print(\"Failed to extract ImageNet dataset:\", e)\n",
        "    exit()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fcI2bgDRdnDV",
        "outputId": "66f9278c-4d56-4cdb-bc45-28e498b9e1b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to extract ImageNet dataset: file could not be opened successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In summary"
      ],
      "metadata": {
        "id": "lMga9u2O_6BF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.applications.resnet.ResNet50(weights='imagenet');\n",
        "# model.summary();\n",
        "len(model.layers)\n",
        "trainableLayerNameList = [layer.name for layer in model.layers if layer.trainable_variables]\n",
        "print(len(trainableLayerNameList));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KhiPXEdPTXZ",
        "outputId": "202ace7b-1c5f-4fc3-9e69-b5c7293a609b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102967424/102967424 [==============================] - 1s 0us/step\n",
            "107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainable = 0\n",
        "\n",
        "# iterate over the layers in the model\n",
        "for layer in model.layers:\n",
        "    # check if the layer has trainable parameters\n",
        "    if layer.trainable_variables:\n",
        "        # if the layer has trainable parameters, increment the counter\n",
        "        trainable += 1\n",
        "\n",
        "# print the number of layers involved in the AllReduce operation\n",
        "print(f'Number of layers with trainable parameters: {trainable}')"
      ],
      "metadata": {
        "id": "ybE7ry0qP1pz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ed9d609-c4cd-4b71-e318-840ef9ff71c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of layers with trainable parameters: 107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "allreduce_layers = 0;\n",
        "for layer in model.layers:\n",
        "    # check if the layer has trainable parameters\n",
        "    if not layer.trainable_variables:\n",
        "        # if the layer has trainable parameters, increment the counter\n",
        "        if \"add\" in layer.name:\n",
        "          allreduce_layers += 1\n",
        "          \n",
        "# print the number of layers involved in the AllReduce operation\n",
        "print(f'Number of layers not involved in AllReduce: {allreduce_layers}')\n",
        "print(f'Number of layers involved in AllReduce: {len(model.layers) - allreduce_layers}')"
      ],
      "metadata": {
        "id": "gCohVvkkRyF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "resnet101 = tf.keras.applications.resnet.ResNet101(weights='imagenet')\n",
        "len(resnet101.layers)\n",
        "trainableLayerNameList = [layer.name for layer in resnet101.layers if layer.trainable_variables]\n",
        "print(len(trainableLayerNameList));\n",
        "allreduce_layers = 0;\n",
        "for layer in resnet101.layers:\n",
        "    # check if the layer has trainable parameters\n",
        "    if not layer.trainable_variables:\n",
        "        if \"add\" in layer.name:\n",
        "          allreduce_layers += 1\n",
        "          # print(layer.name);\n",
        "print(f'Number of layers not involved in AllReduce: {allreduce_layers}')"
      ],
      "metadata": {
        "id": "YQ-t2GJ_gcZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16 = tf.keras.applications.vgg16.VGG16(weights='imagenet')\n",
        "vgg16.summary();\n",
        "print(len(vgg16.layers))\n",
        "trainableLayerNameList = [layer.name for layer in vgg16.layers if layer.trainable_variables]\n",
        "print(len(trainableLayerNameList));\n",
        "allreduce_layers = 0;\n",
        "for layer in vgg16.layers:\n",
        "    # check if the layer has trainable parameters\n",
        "    if not layer.trainable_variables:\n",
        "        if \"add\" in layer.name:\n",
        "          allreduce_layers += 1\n",
        "          # print(layer.name);\n",
        "print(f'Number of layers not involved in AllReduce: {allreduce_layers}')"
      ],
      "metadata": {
        "id": "5Yla5IXykM7C",
        "outputId": "6caadb5f-39be-4cbe-856e-fe3aebee6751",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467096/553467096 [==============================] - 20s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "23\n",
            "16\n",
            "Number of layers not involved in AllReduce: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "conv2d = 0;\n",
        "for layer in vgg16.layers:\n",
        "  if \"_conv\" in layer.name:\n",
        "    conv2d += 1;\n",
        "print(conv2d);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFoMUcturFkA",
        "outputId": "b2bf6d59-6d63-4122-bfa0-1d3d8a260f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainableLayerNameList)"
      ],
      "metadata": {
        "id": "zynCYzoFy_VV",
        "outputId": "216d259c-a9e1-4d6d-ef1d-69f55f37f656",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['block1_conv1', 'block1_conv2', 'block2_conv1', 'block2_conv2', 'block3_conv1', 'block3_conv2', 'block3_conv3', 'block4_conv1', 'block4_conv2', 'block4_conv3', 'block5_conv1', 'block5_conv2', 'block5_conv3']\n"
          ]
        }
      ]
    }
  ]
}